# äº¤äº’å¼å†…å®¹ä¼˜åŒ–åŠŸèƒ½è®¾è®¡æ–‡æ¡£ / Interactive Content Refinement Design Document

## æ¦‚è¿° / Overview

äº¤äº’å¼å†…å®¹ä¼˜åŒ–åŠŸèƒ½æ˜¯æ¡ˆä¾‹æ€»ç»“ç”Ÿæˆå™¨çš„å¢å¼ºæ¨¡å—ï¼Œé€šè¿‡èŠå¤©å¼ç•Œé¢å®ç°ç”¨æˆ·ä¸AIçš„å¤šè½®å¯¹è¯ï¼Œæ”¯æŒå¯¹ç”Ÿæˆå†…å®¹çš„ç²¾ç»†åŒ–è°ƒæ•´ã€‚è¯¥åŠŸèƒ½é‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡ï¼Œä¸ç°æœ‰ç³»ç»Ÿæ— ç¼é›†æˆï¼Œæä¾›ç‰ˆæœ¬ç®¡ç†ã€ä¸Šä¸‹æ–‡æ„ŸçŸ¥å’Œä¸ªæ€§åŒ–å­¦ä¹ èƒ½åŠ›ã€‚

The Interactive Content Refinement feature is an enhancement module for the Case Summary Generator that enables multi-turn conversations between users and AI through a chat-style interface, supporting fine-grained adjustments to generated content. This feature uses a modular design, seamlessly integrates with the existing system, and provides version management, context awareness, and personalized learning capabilities.

## ç³»ç»Ÿæ¶æ„ / System Architecture

### æ•´ä½“æ¶æ„å›¾ / Overall Architecture Diagram

```mermaid
graph TB
    subgraph "ç”¨æˆ·ç•Œé¢å±‚ / UI Layer"
        UI[GradioInterface<br/>Gradio Webç•Œé¢]
        CUI[ChatInterface<br/>èŠå¤©äº¤äº’ç•Œé¢]
        VUI[VersionInterface<br/>ç‰ˆæœ¬ç®¡ç†ç•Œé¢]
    end
    
    subgraph "æ§åˆ¶å±‚ / Controller Layer"
        AC[AppController<br/>åº”ç”¨æ§åˆ¶å™¨]
        RC[RefinementController<br/>ä¼˜åŒ–æ§åˆ¶å™¨]
    end
    
    subgraph "æœåŠ¡å±‚ / Service Layer"
        CS[ConversationService<br/>å¯¹è¯æœåŠ¡]
        VS[VersionService<br/>ç‰ˆæœ¬æœåŠ¡]
        PS[PreferenceService<br/>åå¥½æœåŠ¡]
        MS[ModificationService<br/>ä¿®æ”¹æœåŠ¡]
    end
    
    subgraph "å¤„ç†å±‚ / Processing Layer"
        CP[ConversationProcessor<br/>å¯¹è¯å¤„ç†å™¨]
        MP[ModificationProcessor<br/>ä¿®æ”¹å¤„ç†å™¨]
        VP[VersionProcessor<br/>ç‰ˆæœ¬å¤„ç†å™¨]
    end
    
    subgraph "å­˜å‚¨å±‚ / Storage Layer"
        CS_Store[ConversationStore<br/>å¯¹è¯å­˜å‚¨]
        VS_Store[VersionStore<br/>ç‰ˆæœ¬å­˜å‚¨]
        PS_Store[PreferenceStore<br/>åå¥½å­˜å‚¨]
    end
    
    subgraph "ç°æœ‰ç³»ç»Ÿé›†æˆ / Existing System Integration"
        BC[BedrockClient<br/>Bedrockå®¢æˆ·ç«¯]
        PB[PromptBuilder<br/>æç¤ºè¯æ„å»ºå™¨]
        SPM[SystemPromptManager<br/>ç³»ç»Ÿæç¤ºè¯ç®¡ç†å™¨]
    end
    
    UI --> CUI
    UI --> VUI
    CUI --> RC
    VUI --> RC
    RC --> AC
    RC --> CS
    RC --> VS
    RC --> PS
    RC --> MS
    
    CS --> CP
    VS --> VP
    PS --> CP
    MS --> MP
    
    CP --> CS_Store
    VP --> VS_Store
    CP --> PS_Store
    
    RC --> BC
    RC --> PB
    RC --> SPM
```

### æ–°å¢ç»„ä»¶æ¶æ„è¯¦è¿° / New Component Architecture Details

#### 1. èŠå¤©äº¤äº’ç•Œé¢ (ChatInterface)
- **èŒè´£**: æä¾›èŠå¤©å¼ç”¨æˆ·ç•Œé¢ï¼Œå¤„ç†ç”¨æˆ·è¾“å…¥å’ŒAIå“åº”æ˜¾ç¤º
- **ç‰¹æ€§**: å®æ—¶æ¶ˆæ¯æµã€çŠ¶æ€æŒ‡ç¤ºå™¨ã€æ¶ˆæ¯å†å²æ»šåŠ¨
- **é›†æˆç‚¹**: åµŒå…¥åˆ°ç°æœ‰GradioInterfaceä¸­

#### 2. ä¼˜åŒ–æ§åˆ¶å™¨ (RefinementController)
- **èŒè´£**: åè°ƒäº¤äº’å¼ä¼˜åŒ–æµç¨‹ï¼Œç®¡ç†å¯¹è¯çŠ¶æ€å’Œç‰ˆæœ¬æ§åˆ¶
- **ç‰¹æ€§**: çŠ¶æ€æœºç®¡ç†ã€å¼‚æ­¥å¤„ç†ã€é”™è¯¯æ¢å¤
- **é›†æˆç‚¹**: ä¸AppControllerååŒå·¥ä½œ

#### 3. å¯¹è¯æœåŠ¡ (ConversationService)
- **èŒè´£**: ç®¡ç†å¯¹è¯ä¼šè¯ã€ä¸Šä¸‹æ–‡ç»´æŠ¤ã€æ¶ˆæ¯è·¯ç”±
- **ç‰¹æ€§**: ä¸Šä¸‹æ–‡å‹ç¼©ã€ä¼šè¯æŒä¹…åŒ–ã€å¤šç”¨æˆ·æ”¯æŒ

#### 4. ç‰ˆæœ¬æœåŠ¡ (VersionService)
- **èŒè´£**: å†…å®¹ç‰ˆæœ¬ç®¡ç†ã€å·®å¼‚å¯¹æ¯”ã€ç‰ˆæœ¬å›é€€
- **ç‰¹æ€§**: å¢é‡å­˜å‚¨ã€å¿«ç…§ç®¡ç†ã€ç‰ˆæœ¬æ ‘ç»“æ„

#### 5. åå¥½æœåŠ¡ (PreferenceService)
- **èŒè´£**: ç”¨æˆ·åå¥½å­¦ä¹ ã€æ¨¡å¼è¯†åˆ«ã€ä¸ªæ€§åŒ–å»ºè®®
- **ç‰¹æ€§**: æœºå™¨å­¦ä¹ ç®—æ³•ã€åå¥½æ¨¡å‹ã€é€‚åº”æ€§æ›´æ–°

## æ ¸å¿ƒç»„ä»¶è®¾è®¡ / Core Component Design

### 1. RefinementController (ä¼˜åŒ–æ§åˆ¶å™¨)

```python
class RefinementController:
    """äº¤äº’å¼å†…å®¹ä¼˜åŒ–æ§åˆ¶å™¨"""
    
    def __init__(self, app_controller: AppController):
        self.app_controller = app_controller
        self.conversation_service = ConversationService()
        self.version_service = VersionService()
        self.preference_service = PreferenceService()
        self.modification_service = ModificationService()
        
    # æ ¸å¿ƒæ–¹æ³•
    async def start_refinement_session(self, initial_content: str, user_id: str) -> str
    async def process_user_message(self, message: str, session_id: str) -> Dict[str, Any]
    async def apply_modification(self, modification: Dict, session_id: str) -> str
    def get_version_history(self, session_id: str) -> List[Dict]
    def revert_to_version(self, session_id: str, version_id: str) -> str
```

### 2. ConversationService (å¯¹è¯æœåŠ¡)

```python
class ConversationService:
    """å¯¹è¯ç®¡ç†æœåŠ¡"""
    
    def __init__(self):
        self.conversation_processor = ConversationProcessor()
        self.conversation_store = ConversationStore()
        
    # æ ¸å¿ƒæ–¹æ³•
    def create_session(self, user_id: str, initial_content: str) -> str
    def add_message(self, session_id: str, message: ConversationMessage) -> None
    def get_conversation_history(self, session_id: str) -> List[ConversationMessage]
    def compress_context(self, session_id: str) -> None
    def clear_session(self, session_id: str) -> None
    
    # ä¸Šä¸‹æ–‡ç®¡ç†
    def get_relevant_context(self, session_id: str, query: str) -> str
    def update_context_weights(self, session_id: str, feedback: Dict) -> None
```

### 3. VersionService (ç‰ˆæœ¬æœåŠ¡)

```python
class VersionService:
    """ç‰ˆæœ¬ç®¡ç†æœåŠ¡"""
    
    def __init__(self):
        self.version_processor = VersionProcessor()
        self.version_store = VersionStore()
        
    # æ ¸å¿ƒæ–¹æ³•
    def create_version(self, session_id: str, content: str, modification_type: str) -> str
    def get_version_list(self, session_id: str) -> List[ContentVersion]
    def get_version_content(self, version_id: str) -> str
    def compare_versions(self, version_id1: str, version_id2: str) -> VersionDiff
    def revert_to_version(self, session_id: str, version_id: str) -> str
    
    # ç‰ˆæœ¬ä¼˜åŒ–
    def cleanup_old_versions(self, session_id: str, keep_count: int = 50) -> None
    def create_milestone(self, version_id: str, description: str) -> None
```

### 4. ModificationService (ä¿®æ”¹æœåŠ¡)

```python
class ModificationService:
    """å†…å®¹ä¿®æ”¹æœåŠ¡"""
    
    def __init__(self, bedrock_client: BedrockClient):
        self.bedrock_client = bedrock_client
        self.modification_processor = ModificationProcessor()
        
    # æ ¸å¿ƒæ–¹æ³•
    async def analyze_modification_request(self, request: str, context: str) -> ModificationPlan
    async def apply_modification(self, plan: ModificationPlan, content: str) -> str
    def categorize_modification(self, request: str) -> ModificationType
    def estimate_modification_impact(self, plan: ModificationPlan) -> ImpactAssessment
    
    # ä¿®æ”¹ç±»å‹å¤„ç†
    async def handle_structural_change(self, content: str, instruction: str) -> str
    async def handle_content_addition(self, content: str, instruction: str) -> str
    async def handle_style_adjustment(self, content: str, instruction: str) -> str
    async def handle_format_modification(self, content: str, instruction: str) -> str
```

## æ•°æ®å­˜å‚¨å’Œç®¡ç†è®¾è®¡ / Data Storage and Management Design

### 1. å­˜å‚¨æ¶æ„ / Storage Architecture

```python
class PreferenceStorageManager:
    """åå¥½å­˜å‚¨ç®¡ç†å™¨"""
    
    def __init__(self, storage_config: Dict):
        self.storage_type = storage_config.get('type', 'file_based')  # file_based, database, hybrid
        self.storage_path = storage_config.get('path', './user_preferences')
        self.encryption_enabled = storage_config.get('encryption', True)
        self.backup_enabled = storage_config.get('backup', True)
        
        # å­˜å‚¨ç»“æ„
        self.storage_structure = {
            'user_preferences/': {
                '{user_id}/': {
                    'profile.json': 'ç”¨æˆ·åŸºæœ¬ä¿¡æ¯',
                    'prompts/': {
                        '{prompt_name}.json': 'ç‰¹å®šæç¤ºè¯ä¸‹çš„åå¥½æ•°æ®',
                        '{prompt_name}_history.json': 'äº¤äº’å†å²è®°å½•'
                    },
                    'cross_prompt_patterns.json': 'è·¨æç¤ºè¯çš„é€šç”¨æ¨¡å¼',
                    'export_metadata.json': 'å¯¼å‡ºå…ƒæ•°æ®'
                }
            },
            'global_patterns/': {
                'common_preferences.json': 'å…¨å±€é€šç”¨åå¥½æ¨¡å¼',
                'learning_models.json': 'æœºå™¨å­¦ä¹ æ¨¡å‹å‚æ•°'
            }
        }
```

### 2. æ•°æ®æŒä¹…åŒ–æ–¹æ¡ˆ / Data Persistence Solution

```python
@dataclass
class PreferenceStorageSchema:
    """åå¥½å­˜å‚¨æ¨¡å¼"""
    
    # ç”¨æˆ·åå¥½æ¡£æ¡ˆå­˜å‚¨æ ¼å¼
    user_profile_schema = {
        "user_id": str,
        "created_at": str,  # ISO format
        "updated_at": str,
        "total_interactions": int,
        "active_prompts": List[str],
        "global_preferences": {
            "language": str,
            "timezone": str,
            "interaction_style": str
        }
    }
    
    # æç¤ºè¯ç‰¹å®šåå¥½å­˜å‚¨æ ¼å¼
    prompt_preference_schema = {
        "prompt_name": str,
        "user_id": str,
        "preference_version": str,  # ç”¨äºç‰ˆæœ¬æ§åˆ¶
        "modification_preferences": {
            "structural": float,
            "content_addition": float,
            "content_removal": float,
            "style_adjustment": float,
            "format_modification": float,
            "language_optimization": float
        },
        "style_preferences": {
            "formality_level": str,
            "detail_level": str,
            "technical_depth": str,
            "tone": str,
            "sentence_length": str
        },
        "interaction_patterns": {
            "preferred_modification_size": str,  # small, medium, large
            "feedback_frequency": str,  # immediate, periodic, final
            "guidance_level": str  # minimal, moderate, detailed
        },
        "content_structure_preferences": {
            "preferred_sections": List[str],
            "section_order": List[str],
            "paragraph_length": str,
            "bullet_point_style": str
        },
        "success_metrics": {
            "total_modifications": int,
            "successful_modifications": int,
            "average_satisfaction": float,
            "improvement_trend": List[float]
        },
        "learning_metadata": {
            "confidence_score": float,
            "data_quality": str,
            "last_learning_update": str,
            "learning_stability": float
        }
    }

class PreferenceDataManager:
    """åå¥½æ•°æ®ç®¡ç†å™¨"""
    
    def __init__(self, storage_manager: PreferenceStorageManager):
        self.storage_manager = storage_manager
        self.cache = {}
        self.encryption_key = self.load_encryption_key()
        
    def save_user_preferences(self, user_id: str, prompt_name: str, 
                            preference_data: UserPreferenceProfile) -> bool:
        """ä¿å­˜ç”¨æˆ·åå¥½æ•°æ®"""
        try:
            # 1. åºåˆ—åŒ–åå¥½æ•°æ®
            serialized_data = self.serialize_preference_data(preference_data)
            
            # 2. åŠ å¯†æ•æ„Ÿæ•°æ®ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.storage_manager.encryption_enabled:
                serialized_data = self.encrypt_data(serialized_data)
            
            # 3. ä¿å­˜åˆ°å­˜å‚¨
            file_path = self.get_preference_file_path(user_id, prompt_name)
            self.write_to_storage(file_path, serialized_data)
            
            # 4. æ›´æ–°ç¼“å­˜
            self.update_cache(user_id, prompt_name, preference_data)
            
            # 5. åˆ›å»ºå¤‡ä»½ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.storage_manager.backup_enabled:
                self.create_backup(user_id, prompt_name, serialized_data)
            
            return True
            
        except Exception as e:
            logging.error(f"Failed to save preferences for {user_id}/{prompt_name}: {e}")
            return False
    
    def load_user_preferences(self, user_id: str, prompt_name: str) -> Optional[UserPreferenceProfile]:
        """åŠ è½½ç”¨æˆ·åå¥½æ•°æ®"""
        try:
            # 1. æ£€æŸ¥ç¼“å­˜
            cached_data = self.get_from_cache(user_id, prompt_name)
            if cached_data and self.is_cache_valid(cached_data):
                return cached_data
            
            # 2. ä»å­˜å‚¨åŠ è½½
            file_path = self.get_preference_file_path(user_id, prompt_name)
            if not self.storage_exists(file_path):
                return None
            
            serialized_data = self.read_from_storage(file_path)
            
            # 3. è§£å¯†æ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if self.storage_manager.encryption_enabled:
                serialized_data = self.decrypt_data(serialized_data)
            
            # 4. ååºåˆ—åŒ–
            preference_data = self.deserialize_preference_data(serialized_data)
            
            # 5. æ›´æ–°ç¼“å­˜
            self.update_cache(user_id, prompt_name, preference_data)
            
            return preference_data
            
        except Exception as e:
            logging.error(f"Failed to load preferences for {user_id}/{prompt_name}: {e}")
            return None
```

### 3. å¯¼å‡ºå¯¼å…¥åŠŸèƒ½è®¾è®¡ / Export/Import Functionality Design

```python
class PreferenceExportImportManager:
    """åå¥½å¯¼å‡ºå¯¼å…¥ç®¡ç†å™¨"""
    
    def __init__(self, data_manager: PreferenceDataManager):
        self.data_manager = data_manager
        self.export_formats = ['json', 'yaml', 'csv']
        self.import_validators = {}
        
    def export_user_preferences(self, user_id: str, export_config: Dict) -> Dict[str, Any]:
        """å¯¼å‡ºç”¨æˆ·åå¥½æ•°æ®"""
        export_format = export_config.get('format', 'json')
        include_history = export_config.get('include_history', True)
        include_sensitive = export_config.get('include_sensitive', False)
        prompts_filter = export_config.get('prompts', None)  # Noneè¡¨ç¤ºå…¨éƒ¨
        
        try:
            # 1. æ”¶é›†ç”¨æˆ·æ•°æ®
            user_data = self.collect_user_data(user_id, prompts_filter, include_history)
            
            # 2. è¿‡æ»¤æ•æ„Ÿä¿¡æ¯
            if not include_sensitive:
                user_data = self.filter_sensitive_data(user_data)
            
            # 3. æ·»åŠ å¯¼å‡ºå…ƒæ•°æ®
            export_metadata = {
                'export_timestamp': datetime.now().isoformat(),
                'export_version': '1.0',
                'user_id': user_id,
                'export_config': export_config,
                'data_integrity_hash': self.calculate_data_hash(user_data)
            }
            
            # 4. æ ¼å¼åŒ–å¯¼å‡ºæ•°æ®
            export_package = {
                'metadata': export_metadata,
                'user_profile': user_data['profile'],
                'prompt_preferences': user_data['preferences'],
                'interaction_history': user_data.get('history', []) if include_history else [],
                'cross_prompt_patterns': user_data.get('patterns', {})
            }
            
            # 5. è½¬æ¢ä¸ºæŒ‡å®šæ ¼å¼
            formatted_data = self.format_export_data(export_package, export_format)
            
            # 6. ç”Ÿæˆå¯¼å‡ºæ–‡ä»¶
            export_filename = f"preferences_{user_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.{export_format}"
            
            return {
                'success': True,
                'filename': export_filename,
                'data': formatted_data,
                'metadata': export_metadata
            }
            
        except Exception as e:
            logging.error(f"Failed to export preferences for {user_id}: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def import_user_preferences(self, import_data: Dict, import_config: Dict) -> Dict[str, Any]:
        """å¯¼å…¥ç”¨æˆ·åå¥½æ•°æ®"""
        merge_strategy = import_config.get('merge_strategy', 'replace')  # replace, merge, skip_existing
        validate_integrity = import_config.get('validate_integrity', True)
        backup_existing = import_config.get('backup_existing', True)
        
        try:
            # 1. éªŒè¯å¯¼å…¥æ•°æ®æ ¼å¼
            validation_result = self.validate_import_data(import_data)
            if not validation_result['valid']:
                return {
                    'success': False,
                    'error': f"Invalid import data: {validation_result['errors']}"
                }
            
            # 2. éªŒè¯æ•°æ®å®Œæ•´æ€§
            if validate_integrity:
                integrity_check = self.verify_data_integrity(import_data)
                if not integrity_check['valid']:
                    return {
                        'success': False,
                        'error': f"Data integrity check failed: {integrity_check['error']}"
                    }
            
            user_id = import_data['metadata']['user_id']
            
            # 3. å¤‡ä»½ç°æœ‰æ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if backup_existing:
                backup_result = self.backup_existing_preferences(user_id)
                if not backup_result['success']:
                    logging.warning(f"Failed to backup existing preferences: {backup_result['error']}")
            
            # 4. å¤„ç†å¯¼å…¥ç­–ç•¥
            import_results = []
            
            for prompt_name, preference_data in import_data['prompt_preferences'].items():
                result = self.import_prompt_preferences(
                    user_id, prompt_name, preference_data, merge_strategy
                )
                import_results.append(result)
            
            # 5. å¯¼å…¥è·¨æç¤ºè¯æ¨¡å¼
            if 'cross_prompt_patterns' in import_data:
                pattern_result = self.import_cross_prompt_patterns(
                    user_id, import_data['cross_prompt_patterns']
                )
                import_results.append(pattern_result)
            
            # 6. æ›´æ–°ç”¨æˆ·æ¡£æ¡ˆ
            profile_result = self.import_user_profile(
                user_id, import_data['user_profile'], merge_strategy
            )
            import_results.append(profile_result)
            
            # 7. ç»Ÿè®¡å¯¼å…¥ç»“æœ
            successful_imports = sum(1 for r in import_results if r['success'])
            total_imports = len(import_results)
            
            return {
                'success': successful_imports > 0,
                'total_items': total_imports,
                'successful_items': successful_imports,
                'failed_items': total_imports - successful_imports,
                'details': import_results,
                'import_timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            logging.error(f"Failed to import preferences: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def migrate_preferences(self, from_version: str, to_version: str, user_id: str) -> Dict[str, Any]:
        """è¿ç§»åå¥½æ•°æ®ç‰ˆæœ¬"""
        migration_strategies = {
            ('1.0', '1.1'): self.migrate_v1_0_to_v1_1,
            ('1.1', '2.0'): self.migrate_v1_1_to_v2_0
        }
        
        migration_key = (from_version, to_version)
        if migration_key not in migration_strategies:
            return {
                'success': False,
                'error': f"No migration strategy found for {from_version} -> {to_version}"
            }
        
        try:
            migration_func = migration_strategies[migration_key]
            result = migration_func(user_id)
            
            return {
                'success': True,
                'migrated_version': to_version,
                'migration_details': result
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f"Migration failed: {e}"
            }
```

### 4. ç”¨æˆ·ç•Œé¢é›†æˆ / User Interface Integration

```python
def create_preference_management_interface(self) -> gr.Column:
    """åˆ›å»ºåå¥½ç®¡ç†ç•Œé¢"""
    with gr.Column() as preference_interface:
        gr.Markdown("## ä¸ªæ€§åŒ–åå¥½ç®¡ç† / Personalized Preference Management")
        
        with gr.Tab("åå¥½æ¦‚è§ˆ / Preference Overview"):
            # åå¥½ç»Ÿè®¡æ˜¾ç¤º
            preference_stats = gr.JSON(
                label="åå¥½ç»Ÿè®¡ / Preference Statistics",
                value={}
            )
            
            # å­¦ä¹ è¿›åº¦æ˜¾ç¤º
            learning_progress = gr.Plot(
                label="å­¦ä¹ è¿›åº¦ / Learning Progress"
            )
        
        with gr.Tab("æ•°æ®ç®¡ç† / Data Management"):
            with gr.Row():
                with gr.Column():
                    gr.Markdown("### å¯¼å‡ºåå¥½æ•°æ® / Export Preference Data")
                    
                    export_format = gr.Dropdown(
                        choices=['json', 'yaml', 'csv'],
                        value='json',
                        label="å¯¼å‡ºæ ¼å¼ / Export Format"
                    )
                    
                    include_history = gr.Checkbox(
                        value=True,
                        label="åŒ…å«äº¤äº’å†å² / Include Interaction History"
                    )
                    
                    export_btn = gr.Button("å¯¼å‡ºæ•°æ® / Export Data", variant="primary")
                    export_status = gr.Textbox(label="å¯¼å‡ºçŠ¶æ€ / Export Status")
                
                with gr.Column():
                    gr.Markdown("### å¯¼å…¥åå¥½æ•°æ® / Import Preference Data")
                    
                    import_file = gr.File(
                        label="é€‰æ‹©å¯¼å…¥æ–‡ä»¶ / Select Import File",
                        file_types=['.json', '.yaml', '.csv']
                    )
                    
                    merge_strategy = gr.Dropdown(
                        choices=['replace', 'merge', 'skip_existing'],
                        value='merge',
                        label="åˆå¹¶ç­–ç•¥ / Merge Strategy"
                    )
                    
                    import_btn = gr.Button("å¯¼å…¥æ•°æ® / Import Data", variant="secondary")
                    import_status = gr.Textbox(label="å¯¼å…¥çŠ¶æ€ / Import Status")
        
        with gr.Tab("åå¥½é‡ç½® / Preference Reset"):
            gr.Markdown("### âš ï¸ å±é™©æ“ä½œ / Dangerous Operations")
            
            reset_options = gr.CheckboxGroup(
                choices=[
                    "é‡ç½®æ‰€æœ‰åå¥½ / Reset All Preferences",
                    "é‡ç½®å­¦ä¹ å†å² / Reset Learning History", 
                    "é‡ç½®ä¸ªæ€§åŒ–æ¨¡å‹ / Reset Personalization Models"
                ],
                label="é‡ç½®é€‰é¡¹ / Reset Options"
            )
            
            confirm_reset = gr.Checkbox(
                label="æˆ‘ç¡®è®¤è¦æ‰§è¡Œé‡ç½®æ“ä½œ / I confirm the reset operation"
            )
            
            reset_btn = gr.Button("æ‰§è¡Œé‡ç½® / Execute Reset", variant="stop")
            reset_status = gr.Textbox(label="é‡ç½®çŠ¶æ€ / Reset Status")
        
        return preference_interface
```

## æ•°æ®æ¨¡å‹è®¾è®¡ / Data Model Design

### 1. å¯¹è¯ç›¸å…³æ¨¡å‹ / Conversation Models

```python
@dataclass
class ConversationMessage:
    """å¯¹è¯æ¶ˆæ¯æ¨¡å‹"""
    id: str
    session_id: str
    sender: str  # 'user' or 'ai'
    content: str
    timestamp: datetime
    message_type: str  # 'text', 'modification_request', 'system'
    metadata: Dict[str, Any]

@dataclass
class ConversationSession:
    """å¯¹è¯ä¼šè¯æ¨¡å‹"""
    id: str
    user_id: str
    initial_content: str
    current_content: str
    created_at: datetime
    updated_at: datetime
    status: str  # 'active', 'paused', 'completed'
    context_summary: str
    preferences: Dict[str, Any]
```

### 2. ç‰ˆæœ¬ç›¸å…³æ¨¡å‹ / Version Models

```python
@dataclass
class ContentVersion:
    """å†…å®¹ç‰ˆæœ¬æ¨¡å‹"""
    id: str
    session_id: str
    content: str
    version_number: int
    parent_version_id: Optional[str]
    modification_type: str
    modification_description: str
    created_at: datetime
    is_milestone: bool
    metadata: Dict[str, Any]

@dataclass
class VersionDiff:
    """ç‰ˆæœ¬å·®å¼‚æ¨¡å‹"""
    version1_id: str
    version2_id: str
    additions: List[str]
    deletions: List[str]
    modifications: List[Dict[str, str]]
    similarity_score: float
```

### 3. ä¿®æ”¹ç›¸å…³æ¨¡å‹ / Modification Models

```python
@dataclass
class ModificationPlan:
    """ä¿®æ”¹è®¡åˆ’æ¨¡å‹"""
    id: str
    request: str
    modification_type: ModificationType
    target_sections: List[str]
    instructions: List[str]
    estimated_impact: ImpactLevel
    confidence_score: float

class ModificationType(Enum):
    """ä¿®æ”¹ç±»å‹æšä¸¾"""
    STRUCTURAL = "structural"
    CONTENT_ADDITION = "content_addition"
    CONTENT_REMOVAL = "content_removal"
    STYLE_ADJUSTMENT = "style_adjustment"
    FORMAT_MODIFICATION = "format_modification"
    LANGUAGE_OPTIMIZATION = "language_optimization"

class ImpactLevel(Enum):
    """å½±å“çº§åˆ«æšä¸¾"""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"
```

## ç”¨æˆ·ç•Œé¢ä¼˜åŒ–è®¾è®¡ / User Interface Enhancement Design

### 1. ä¿å®ˆçš„ç•Œé¢é›†æˆæ–¹æ¡ˆ / Conservative Interface Integration Approach

åŸºäºç°æœ‰å·²æµ‹è¯•é€šè¿‡çš„ç»„ä»¶ï¼Œé‡‡ç”¨æœ€å°åŒ–ä¿®æ”¹çš„æ–¹å¼é›†æˆäº¤äº’å¼ä¼˜åŒ–åŠŸèƒ½ï¼š

```python
class RefinementIntegrationInterface:
    """äº¤äº’å¼ä¼˜åŒ–åŠŸèƒ½é›†æˆç•Œé¢ - ä¿ç•™ç°æœ‰ç»„ä»¶"""
    
    def __init__(self, existing_gradio_interface: GradioInterface):
        """åŸºäºç°æœ‰ç•Œé¢è¿›è¡Œæ‰©å±•"""
        self.existing_interface = existing_gradio_interface
        self.app_controller = existing_gradio_interface.app_controller
        
    def integrate_refinement_features(self) -> gr.Blocks:
        """åœ¨ç°æœ‰ç•Œé¢ä¸­é›†æˆä¼˜åŒ–åŠŸèƒ½"""
        
        # ä¿ç•™ç°æœ‰çš„ä¸»ç•Œé¢ç»“æ„
        with gr.Blocks(
            title=self.app_controller.get_app_config().get("title", "æ¡ˆä¾‹æ€»ç»“ç”Ÿæˆå™¨"), 
            theme=gr.themes.Soft()
        ) as interface:
            
            # ä¿ç•™ç°æœ‰çš„æ ‡é¢˜
            gr.Markdown(
                f"# {self.app_controller.get_app_config().get('title', 'æ¡ˆä¾‹æ€»ç»“ç”Ÿæˆå™¨ / Case Summary Generator')}"
            )
            
            # ä¿ç•™ç°æœ‰çš„ä¸»è¦åŠŸèƒ½åŒºåŸŸ
            with gr.Row():
                with gr.Column(scale=2):
                    # ä¿ç•™ç°æœ‰çš„æ¡ˆä¾‹è¾“å…¥åŒºåŸŸ
                    case_input = gr.Textbox(
                        label="æ¡ˆä¾‹è¾“å…¥ / Case Input",
                        placeholder="è¯·è¾“å…¥éœ€è¦æ€»ç»“çš„æ¡ˆä¾‹å†…å®¹... / Please enter the case content to summarize...",
                        lines=8,
                        max_lines=15,
                    )
                    
                    # ä¿ç•™ç°æœ‰çš„ç³»ç»Ÿæç¤ºè¯ç®¡ç†ï¼ˆæ¥è‡ªç°æœ‰çš„prompt_uiç»„ä»¶ï¼‰
                    with gr.Group():
                        gr.Markdown("### ç³»ç»Ÿæç¤ºè¯ç®¡ç† / System Prompt Management")
                        prompt_selector = self.existing_interface.prompt_ui.create_prompt_selector()
                        prompt_editor = self.existing_interface.prompt_ui.create_prompt_editor()
                        
                        # ä¿ç•™ç°æœ‰çš„æç¤ºè¯ç®¡ç†é¢æ¿
                        (
                            management_panel,
                            new_btn,
                            save_btn,
                            delete_btn,
                            status_text,
                        ) = self.existing_interface.prompt_ui.create_prompt_management_panel()
                
                with gr.Column(scale=1):
                    # ä¿ç•™ç°æœ‰çš„æ¨¡å‹é€‰æ‹©
                    model_dropdown = gr.Dropdown(
                        label="é€‰æ‹©æ¨¡å‹ / Select Model",
                        choices=[],
                        value=None,
                        interactive=True,
                    )
                    
                    # ä¿ç•™ç°æœ‰çš„æ§åˆ¶æŒ‰é’®
                    with gr.Row():
                        generate_btn = gr.Button(
                            "ç”Ÿæˆæ€»ç»“ / Generate Summary", variant="primary"
                        )
                        refresh_btn = gr.Button(
                            "åˆ·æ–°æ¨¡å‹ / Refresh Models", variant="secondary"
                        )
                    
                    # ä¿ç•™ç°æœ‰çš„çŠ¶æ€æ˜¾ç¤º
                    status_display = gr.Textbox(
                        label="çŠ¶æ€ / Status",
                        value="å°±ç»ª / Ready",
                        interactive=False,
                        lines=2,
                    )
            
            # ä¿ç•™ç°æœ‰çš„è¾“å‡ºåŒºåŸŸï¼Œå¹¶æ·»åŠ ä¼˜åŒ–åŠŸèƒ½
            with gr.Row():
                with gr.Column(scale=2):
                    # ä¿ç•™ç°æœ‰çš„è¾“å‡ºæ–‡æœ¬æ¡†
                    output_text = gr.Textbox(
                        label="ç”Ÿæˆçš„æ¡ˆä¾‹æ€»ç»“ / Generated Case Summary",
                        lines=12,
                        max_lines=20,
                        interactive=False,
                    )
                
                # æ–°å¢ï¼šäº¤äº’å¼ä¼˜åŒ–åŒºåŸŸï¼ˆä½œä¸ºç‹¬ç«‹åˆ—ï¼‰
                with gr.Column(scale=1):
                    self.create_refinement_panel()
            
            # æ–°å¢ï¼šç‰ˆæœ¬ç®¡ç†åŒºåŸŸï¼ˆå¯æŠ˜å ï¼Œä¸å½±å“ç°æœ‰å¸ƒå±€ï¼‰
            with gr.Accordion("ğŸ“š ç‰ˆæœ¬å†å² / Version History", open=False):
                self.create_version_management_panel()
            
            # ä¿ç•™ç°æœ‰çš„äº‹ä»¶ç»‘å®šé€»è¾‘
            self.bind_existing_events(
                case_input, model_dropdown, prompt_editor, generate_btn, 
                refresh_btn, output_text, status_display
            )
            
            # æ·»åŠ æ–°çš„ä¼˜åŒ–åŠŸèƒ½äº‹ä»¶ç»‘å®š
            self.bind_refinement_events()
            
        return interface
    
    def create_refinement_panel(self):
        """åˆ›å»ºäº¤äº’å¼ä¼˜åŒ–é¢æ¿"""
        gr.Markdown("### ğŸ’¬ å†…å®¹ä¼˜åŒ– / Content Refinement")
        
        # èŠå¤©å†å²æ˜¾ç¤º
        self.chat_history = gr.Chatbot(
            label="å¯¹è¯å†å² / Chat History",
            height=300,
            show_label=True,
            bubble_full_width=False,
            avatar_images=("ğŸ‘¤", "ğŸ¤–")
        )
        
        # ç”¨æˆ·è¾“å…¥åŒºåŸŸ
        with gr.Row():
            self.user_input = gr.Textbox(
                placeholder="è¯·æè¿°æ‚¨å¸Œæœ›çš„ä¿®æ”¹... / Describe your desired changes...",
                container=False,
                scale=4,
                show_label=False
            )
            self.send_btn = gr.Button("å‘é€ / Send", variant="primary", scale=1)
        
        # å¿«æ·æ“ä½œæŒ‰é’®
        with gr.Row():
            self.add_detail_btn = gr.Button("â• æ·»åŠ ç»†èŠ‚", size="sm")
            self.adjust_style_btn = gr.Button("ğŸ¨ è°ƒæ•´é£æ ¼", size="sm")
            self.simplify_btn = gr.Button("âœ‚ï¸ ç®€åŒ–å†…å®¹", size="sm")
        
        # å¯¹è¯æ§åˆ¶
        with gr.Row():
            self.clear_chat_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯", size="sm")
            self.undo_btn = gr.Button("â†©ï¸ æ’¤é”€ä¿®æ”¹", size="sm")
    
    def create_version_management_panel(self):
        """åˆ›å»ºç‰ˆæœ¬ç®¡ç†é¢æ¿"""
        with gr.Row():
            with gr.Column(scale=2):
                self.version_list = gr.Dataframe(
                    headers=["ç‰ˆæœ¬", "æ—¶é—´", "ä¿®æ”¹ç±»å‹", "æè¿°"],
                    datatype=["str", "str", "str", "str"],
                    label="ç‰ˆæœ¬åˆ—è¡¨ / Version List",
                    interactive=True,
                    height=150
                )
            
            with gr.Column(scale=1):
                with gr.Column():
                    self.view_version_btn = gr.Button("ğŸ‘ï¸ æŸ¥çœ‹ç‰ˆæœ¬", size="sm")
                    self.compare_btn = gr.Button("ğŸ” å¯¹æ¯”ç‰ˆæœ¬", size="sm")
                    self.revert_btn = gr.Button("â†©ï¸ å›é€€ç‰ˆæœ¬", size="sm")
                    self.milestone_btn = gr.Button("ğŸ·ï¸ åˆ›å»ºé‡Œç¨‹ç¢‘", size="sm")
        
        # ç‰ˆæœ¬å¯¹æ¯”æ˜¾ç¤ºåŒºåŸŸ
        self.version_diff_display = gr.HTML(
            label="ç‰ˆæœ¬å¯¹æ¯” / Version Comparison",
            visible=False
        )
    
    def bind_existing_events(self, case_input, model_dropdown, prompt_editor, 
                           generate_btn, refresh_btn, output_text, status_display):
        """ç»‘å®šç°æœ‰åŠŸèƒ½çš„äº‹ä»¶ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰"""
        
        # ä¿ç•™ç°æœ‰çš„ç”Ÿæˆæ€»ç»“äº‹ä»¶
        generate_btn.click(
            fn=self.existing_interface._generate_summary,
            inputs=[case_input, model_dropdown, prompt_editor],
            outputs=[output_text, status_display],
        )
        
        # ä¿ç•™ç°æœ‰çš„åˆ·æ–°æ¨¡å‹äº‹ä»¶
        refresh_btn.click(
            fn=self.existing_interface._refresh_models, 
            outputs=[model_dropdown, status_display]
        )
        
        # ä¿ç•™ç°æœ‰çš„ç•Œé¢åŠ è½½äº‹ä»¶
        # è¿™é‡Œä¼šè°ƒç”¨ç°æœ‰çš„åˆå§‹åŒ–é€»è¾‘
    
    def bind_refinement_events(self):
        """ç»‘å®šæ–°çš„ä¼˜åŒ–åŠŸèƒ½äº‹ä»¶"""
        
        # å‘é€æ¶ˆæ¯äº‹ä»¶
        self.send_btn.click(
            fn=self.handle_user_message,
            inputs=[self.user_input],
            outputs=[self.chat_history, self.user_input]
        )
        
        # å¿«æ·æ“ä½œäº‹ä»¶
        self.add_detail_btn.click(
            fn=lambda: self.handle_quick_suggestion("è¯·æ·»åŠ æ›´å¤šç»†èŠ‚å’Œå…·ä½“ä¿¡æ¯"),
            outputs=[self.chat_history]
        )
        
        self.adjust_style_btn.click(
            fn=lambda: self.handle_quick_suggestion("è¯·è°ƒæ•´è¯­è¨€é£æ ¼ï¼Œä½¿å…¶æ›´åŠ ä¸“ä¸š"),
            outputs=[self.chat_history]
        )
        
        self.simplify_btn.click(
            fn=lambda: self.handle_quick_suggestion("è¯·ç®€åŒ–å†…å®¹ï¼Œä½¿å…¶æ›´åŠ ç®€æ´æ˜äº†"),
            outputs=[self.chat_history]
        )
        
        # å¯¹è¯æ§åˆ¶äº‹ä»¶
        self.clear_chat_btn.click(
            fn=self.clear_chat_history,
            outputs=[self.chat_history]
        )
        
        # ç‰ˆæœ¬ç®¡ç†äº‹ä»¶
        self.view_version_btn.click(
            fn=self.view_selected_version,
            inputs=[self.version_list],
            outputs=[self.version_diff_display]
        )
        
        self.compare_btn.click(
            fn=self.compare_versions,
            inputs=[self.version_list],
            outputs=[self.version_diff_display]
        )
    
    def handle_user_message(self, message: str):
        """å¤„ç†ç”¨æˆ·æ¶ˆæ¯"""
        if not message.strip():
            return self.chat_history.value, ""
        
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°èŠå¤©å†å²
        updated_history = self.chat_history.value + [(message, None)]
        
        # è¿™é‡Œä¼šè°ƒç”¨åç«¯çš„ä¼˜åŒ–å¤„ç†é€»è¾‘
        # ai_response = self.process_refinement_request(message)
        ai_response = f"æˆ‘ç†è§£æ‚¨å¸Œæœ›ï¼š{message}ã€‚è®©æˆ‘æ¥å¸®æ‚¨ä¼˜åŒ–å†…å®¹ã€‚"
        
        # æ·»åŠ AIå“åº”
        updated_history[-1] = (message, ai_response)
        
        return updated_history, ""  # æ¸…ç©ºè¾“å…¥æ¡†
    
    def handle_quick_suggestion(self, suggestion: str):
        """å¤„ç†å¿«æ·å»ºè®®"""
        return self.handle_user_message(suggestion)[0]
    
    def clear_chat_history(self):
        """æ¸…ç©ºèŠå¤©å†å²"""
        return []
```

### 2. ä¸ªæ€§åŒ–Promptæ–‡ä»¶ç®¡ç†ç•Œé¢ / Personalized Prompt File Management Interface

```python
def create_personalized_prompt_management(self):
    """åˆ›å»ºä¸ªæ€§åŒ–promptç®¡ç†ç•Œé¢ï¼ˆä½œä¸ºç‹¬ç«‹æ ‡ç­¾é¡µï¼‰"""
    
    with gr.Tab("ğŸ¯ ä¸ªæ€§åŒ–Prompt / Personalized Prompts"):
        gr.Markdown("### ä¸ªæ€§åŒ–Promptæ–‡ä»¶ç®¡ç† / Personalized Prompt File Management")
        
        with gr.Row():
            with gr.Column(scale=1):
                # å½“å‰ç”¨æˆ·çš„ä¸ªæ€§åŒ–promptåˆ—è¡¨
                gr.Markdown("#### ğŸ“‹ æˆ‘çš„ä¸ªæ€§åŒ–Prompt / My Personalized Prompts")
                
                self.personalized_prompt_list = gr.Dataframe(
                    headers=["åœºæ™¯", "ç‰ˆæœ¬", "åˆ›å»ºæ—¶é—´", "çŠ¶æ€"],
                    datatype=["str", "str", "str", "str"],
                    label="ä¸ªæ€§åŒ–Promptåˆ—è¡¨ / Personalized Prompt List",
                    interactive=True
                )
                
                with gr.Row():
                    self.view_prompt_btn = gr.Button("ğŸ‘ï¸ æŸ¥çœ‹", size="sm")
                    self.activate_prompt_btn = gr.Button("âœ… æ¿€æ´»", size="sm")
                    self.delete_prompt_btn = gr.Button("ğŸ—‘ï¸ åˆ é™¤", size="sm")
            
            with gr.Column(scale=2):
                # Promptå†…å®¹æ˜¾ç¤ºå’Œç¼–è¾‘
                gr.Markdown("#### ğŸ“ Promptå†…å®¹ / Prompt Content")
                
                self.prompt_content_display = gr.Textbox(
                    label="",
                    lines=15,
                    max_lines=20,
                    interactive=False
                )
                
                with gr.Row():
                    self.edit_prompt_btn = gr.Button("âœï¸ ç¼–è¾‘", size="sm")
                    self.save_prompt_btn = gr.Button("ğŸ’¾ ä¿å­˜", size="sm")
                    self.export_prompt_btn = gr.Button("ğŸ“¤ å¯¼å‡º", size="sm")
        
        # å¯¼å…¥å¯¼å‡ºåŒºåŸŸ
        with gr.Accordion("ğŸ“ å¯¼å…¥å¯¼å‡º / Import Export", open=False):
            with gr.Row():
                with gr.Column():
                    gr.Markdown("#### ğŸ“¤ å¯¼å‡ºä¸ªæ€§åŒ–Prompt / Export Personalized Prompts")
                    
                    self.export_format = gr.Dropdown(
                        choices=["JSON", "YAML"],
                        value="JSON",
                        label="å¯¼å‡ºæ ¼å¼ / Export Format"
                    )
                    
                    self.export_all_btn = gr.Button("å¯¼å‡ºå…¨éƒ¨ / Export All", variant="primary")
                    self.export_status = gr.Textbox(label="å¯¼å‡ºçŠ¶æ€ / Export Status")
                
                with gr.Column():
                    gr.Markdown("#### ğŸ“¥ å¯¼å…¥ä¸ªæ€§åŒ–Prompt / Import Personalized Prompts")
                    
                    self.import_file = gr.File(
                        label="é€‰æ‹©å¯¼å…¥æ–‡ä»¶ / Select Import File",
                        file_types=['.json', '.yaml']
                    )
                    
                    self.import_btn = gr.Button("å¯¼å…¥ / Import", variant="secondary")
                    self.import_status = gr.Textbox(label="å¯¼å…¥çŠ¶æ€ / Import Status")
```

### 3. æœ€å°åŒ–ä¿®æ”¹åŸåˆ™ / Minimal Modification Principles

#### **ä¿ç•™ç°æœ‰ç»„ä»¶**
1. **å®Œå…¨ä¿ç•™**ç°æœ‰çš„GradioInterfaceç±»å’Œæ‰€æœ‰å·²æµ‹è¯•çš„ç»„ä»¶
2. **ç»§æ‰¿æ‰©å±•**è€Œä¸æ˜¯é‡å†™ï¼Œç¡®ä¿ç°æœ‰åŠŸèƒ½ä¸å—å½±å“
3. **å¢é‡æ·»åŠ **æ–°åŠŸèƒ½ï¼Œé€šè¿‡æ–°çš„é¢æ¿å’Œæ ‡ç­¾é¡µå®ç°

#### **åŠŸèƒ½é›†æˆç­–ç•¥**
1. **ä¾§è¾¹é¢æ¿**ï¼šå°†èŠå¤©ä¼˜åŒ–åŠŸèƒ½ä½œä¸ºä¾§è¾¹é¢æ¿æ·»åŠ 
2. **æŠ˜å åŒºåŸŸ**ï¼šç‰ˆæœ¬ç®¡ç†ç­‰é«˜çº§åŠŸèƒ½æ”¾åœ¨å¯æŠ˜å åŒºåŸŸ
3. **ç‹¬ç«‹æ ‡ç­¾é¡µ**ï¼šä¸ªæ€§åŒ–promptç®¡ç†ä½œä¸ºç‹¬ç«‹æ ‡ç­¾é¡µ

#### **äº‹ä»¶å¤„ç†å…¼å®¹**
1. **ä¿æŒç°æœ‰äº‹ä»¶ç»‘å®š**ä¸å˜
2. **æ–°å¢äº‹ä»¶å¤„ç†**é€šè¿‡æ–°çš„æ–¹æ³•å®ç°
3. **æ•°æ®æµéš”ç¦»**ï¼Œé¿å…å½±å“ç°æœ‰æ•°æ®å¤„ç†é€»è¾‘

è¿™æ ·çš„è®¾è®¡ç¡®ä¿äº†ï¼š
- âœ… ç°æœ‰åŠŸèƒ½å®Œå…¨ä¸å—å½±å“
- âœ… æ–°åŠŸèƒ½ä¸åå°æœåŠ¡æ­£ç¡®å¯¹åº”
- âœ… ç”¨æˆ·ç•Œé¢æ¸…æ™°æ˜“æ‡‚
- âœ… å¼€å‘é£é™©æœ€å°åŒ–

### 1. ä¸»ç•Œé¢å¸ƒå±€é‡æ„ / Main Interface Layout Restructuring

åŸºäºåŠŸèƒ½å½’ç±»å’Œç”¨æˆ·è®¤çŸ¥æµç¨‹ï¼Œé‡æ–°è®¾è®¡ä¸»ç•Œé¢å¸ƒå±€ï¼š

```python
class EnhancedGradioInterface:
    """å¢å¼ºçš„Gradioç•Œé¢ - é‡æ–°ç»„ç»‡åŠŸèƒ½å¸ƒå±€"""
    
    def create_main_interface(self) -> gr.Blocks:
        """åˆ›å»ºé‡æ–°è®¾è®¡çš„ä¸»ç•Œé¢"""
        with gr.Blocks(title="æ™ºèƒ½æ¡ˆä¾‹æ€»ç»“ç”Ÿæˆå™¨", theme=gr.themes.Soft()) as interface:
            
            # é¡¶éƒ¨æ ‡é¢˜å’ŒçŠ¶æ€æ 
            self.create_header_section()
            
            # ä¸»è¦åŠŸèƒ½åŒºåŸŸ - ä½¿ç”¨æ ‡ç­¾é¡µç»„ç»‡
            with gr.Tabs() as main_tabs:
                
                # æ ‡ç­¾é¡µ1: å†…å®¹ç”Ÿæˆå’Œä¼˜åŒ–
                with gr.Tab("ğŸ“ å†…å®¹ç”Ÿæˆä¸ä¼˜åŒ– / Content Generation & Refinement", id="generation"):
                    self.create_generation_and_refinement_section()
                
                # æ ‡ç­¾é¡µ2: ç³»ç»Ÿé…ç½®
                with gr.Tab("âš™ï¸ ç³»ç»Ÿé…ç½® / System Configuration", id="configuration"):
                    self.create_configuration_section()
                
                # æ ‡ç­¾é¡µ3: ä¸ªäººåå¥½ç®¡ç†
                with gr.Tab("ğŸ‘¤ ä¸ªäººåå¥½ / Personal Preferences", id="preferences"):
                    self.create_preference_management_section()
                
                # æ ‡ç­¾é¡µ4: æ•°æ®ç®¡ç†
                with gr.Tab("ğŸ’¾ æ•°æ®ç®¡ç† / Data Management", id="data"):
                    self.create_data_management_section()
            
            # åº•éƒ¨çŠ¶æ€å’Œå¸®åŠ©ä¿¡æ¯
            self.create_footer_section()
            
        return interface
    
    def create_header_section(self):
        """åˆ›å»ºé¡¶éƒ¨æ ‡é¢˜å’ŒçŠ¶æ€æ """
        with gr.Row():
            with gr.Column(scale=3):
                gr.Markdown("# ğŸ¤– æ™ºèƒ½æ¡ˆä¾‹æ€»ç»“ç”Ÿæˆå™¨ / Intelligent Case Summary Generator")
                gr.Markdown("*åŸºäºAIçš„äº¤äº’å¼å†…å®¹ç”Ÿæˆå’Œä¼˜åŒ–å¹³å° / AI-powered Interactive Content Generation and Refinement Platform*")
            
            with gr.Column(scale=1):
                # ç³»ç»ŸçŠ¶æ€æŒ‡ç¤ºå™¨
                system_status = gr.HTML(
                    value=self.get_system_status_html(),
                    label="ç³»ç»ŸçŠ¶æ€ / System Status"
                )
                
                # å¿«é€Ÿæ“ä½œæŒ‰é’®
                with gr.Row():
                    help_btn = gr.Button("â“ å¸®åŠ©", size="sm")
                    settings_btn = gr.Button("âš™ï¸ è®¾ç½®", size="sm")
    
    def create_generation_and_refinement_section(self):
        """åˆ›å»ºå†…å®¹ç”Ÿæˆå’Œä¼˜åŒ–åŒºåŸŸ"""
        with gr.Row():
            # å·¦ä¾§ï¼šè¾“å…¥å’Œé…ç½®åŒºåŸŸ
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“‹ è¾“å…¥é…ç½® / Input Configuration")
                
                # ç³»ç»Ÿæç¤ºè¯é€‰æ‹©
                with gr.Group():
                    gr.Markdown("#### ğŸ¯ ç³»ç»Ÿæç¤ºè¯ / System Prompt")
                    prompt_selector = self.prompt_ui.create_prompt_selector()
                    
                    with gr.Row():
                        edit_prompt_btn = gr.Button("ç¼–è¾‘ / Edit", size="sm")
                        new_prompt_btn = gr.Button("æ–°å»º / New", size="sm")
                        manage_prompts_btn = gr.Button("ç®¡ç† / Manage", size="sm")
                
                # æ¨¡å‹é€‰æ‹©
                with gr.Group():
                    gr.Markdown("#### ğŸ§  AIæ¨¡å‹é€‰æ‹© / AI Model Selection")
                    model_selector = gr.Dropdown(
                        label="é€‰æ‹©æ¨¡å‹ / Select Model",
                        info="ä¸åŒæ¨¡å‹æœ‰ä¸åŒçš„ç‰¹ç‚¹å’Œèƒ½åŠ› / Different models have different characteristics"
                    )
                    refresh_models_btn = gr.Button("ğŸ”„ åˆ·æ–°æ¨¡å‹åˆ—è¡¨", size="sm")
                
                # æ¡ˆä¾‹è¾“å…¥
                with gr.Group():
                    gr.Markdown("#### ğŸ“ æ¡ˆä¾‹è¾“å…¥ / Case Input")
                    case_input = gr.Textbox(
                        label="è¯·è¾“å…¥éœ€è¦æ€»ç»“çš„æ¡ˆä¾‹å†…å®¹ / Enter case content to summarize",
                        placeholder="åœ¨æ­¤è¾“å…¥æ‚¨çš„æ¡ˆä¾‹å†…å®¹... / Enter your case content here...",
                        lines=8,
                        max_lines=15
                    )
                    
                    with gr.Row():
                        word_count = gr.HTML("å­—æ•°ç»Ÿè®¡: 0 / Word count: 0")
                        clear_input_btn = gr.Button("æ¸…ç©º / Clear", size="sm")
                
                # ç”ŸæˆæŒ‰é’®
                generate_btn = gr.Button(
                    "ğŸš€ ç”Ÿæˆæ¡ˆä¾‹æ€»ç»“ / Generate Case Summary", 
                    variant="primary", 
                    size="lg"
                )
            
            # å³ä¾§ï¼šç»“æœæ˜¾ç¤ºå’Œä¼˜åŒ–åŒºåŸŸ
            with gr.Column(scale=2):
                gr.Markdown("### ğŸ“„ ç”Ÿæˆç»“æœä¸äº¤äº’ä¼˜åŒ– / Generated Results & Interactive Refinement")
                
                # ç»“æœæ˜¾ç¤ºåŒºåŸŸ
                with gr.Group():
                    gr.Markdown("#### ğŸ“‹ å½“å‰å†…å®¹ / Current Content")
                    
                    # å†…å®¹æ˜¾ç¤ºå’Œç‰ˆæœ¬ä¿¡æ¯
                    with gr.Row():
                        current_version_info = gr.HTML(
                            value="<span style='color: #666;'>ç‰ˆæœ¬: åˆå§‹ç‰ˆæœ¬ / Version: Initial</span>"
                        )
                        content_stats = gr.HTML(
                            value="<span style='color: #666;'>å­—æ•°: 0 | æ®µè½: 0 / Words: 0 | Paragraphs: 0</span>"
                        )
                    
                    # ä¸»è¦å†…å®¹æ˜¾ç¤º
                    generated_content = gr.Textbox(
                        label="",
                        lines=12,
                        max_lines=20,
                        interactive=False,
                        show_copy_button=True
                    )
                    
                    # å†…å®¹æ“ä½œæŒ‰é’®
                    with gr.Row():
                        copy_content_btn = gr.Button("ğŸ“‹ å¤åˆ¶", size="sm")
                        export_content_btn = gr.Button("ğŸ’¾ å¯¼å‡º", size="sm")
                        share_content_btn = gr.Button("ğŸ”— åˆ†äº«", size="sm")
                
                # äº¤äº’ä¼˜åŒ–åŒºåŸŸ
                with gr.Group():
                    gr.Markdown("#### ğŸ’¬ æ™ºèƒ½å¯¹è¯ä¼˜åŒ– / Intelligent Conversation Refinement")
                    
                    # èŠå¤©å†å²æ˜¾ç¤º
                    chat_history = gr.Chatbot(
                        label="",
                        height=300,
                        show_label=False,
                        bubble_full_width=False,
                        avatar_images=("ğŸ‘¤", "ğŸ¤–")
                    )
                    
                    # ç”¨æˆ·è¾“å…¥åŒºåŸŸ
                    with gr.Row():
                        user_message = gr.Textbox(
                            placeholder="å‘Šè¯‰æˆ‘æ‚¨å¸Œæœ›å¦‚ä½•æ”¹è¿›å†…å®¹... / Tell me how you'd like to improve the content...",
                            container=False,
                            scale=4,
                            show_label=False
                        )
                        send_message_btn = gr.Button("å‘é€ / Send", variant="primary", scale=1)
                    
                    # å¿«æ·å»ºè®®æŒ‰é’®
                    with gr.Row():
                        gr.Markdown("**å¿«æ·å»ºè®® / Quick Suggestions:**")
                    
                    with gr.Row():
                        add_details_btn = gr.Button("â• æ·»åŠ ç»†èŠ‚", size="sm")
                        adjust_style_btn = gr.Button("ğŸ¨ è°ƒæ•´é£æ ¼", size="sm")
                        restructure_btn = gr.Button("ğŸ”„ é‡æ–°ç»„ç»‡", size="sm")
                        simplify_btn = gr.Button("âœ‚ï¸ ç®€åŒ–å†…å®¹", size="sm")
                    
                    # å¯¹è¯æ§åˆ¶æŒ‰é’®
                    with gr.Row():
                        clear_chat_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯", size="sm")
                        export_chat_btn = gr.Button("ğŸ’¾ å¯¼å‡ºå¯¹è¯", size="sm")
                        undo_last_btn = gr.Button("â†©ï¸ æ’¤é”€ä¸Šæ¬¡ä¿®æ”¹", size="sm")
        
        # ç‰ˆæœ¬ç®¡ç†åŒºåŸŸï¼ˆå¯æŠ˜å ï¼‰
        with gr.Accordion("ğŸ“š ç‰ˆæœ¬å†å²ç®¡ç† / Version History Management", open=False):
            self.create_version_management_section()
    
    def create_version_management_section(self):
        """åˆ›å»ºç‰ˆæœ¬ç®¡ç†åŒºåŸŸ"""
        with gr.Row():
            with gr.Column(scale=2):
                # ç‰ˆæœ¬åˆ—è¡¨
                version_history = gr.Dataframe(
                    headers=["ç‰ˆæœ¬", "æ—¶é—´", "ä¿®æ”¹ç±»å‹", "æè¿°", "æ»¡æ„åº¦"],
                    datatype=["str", "str", "str", "str", "number"],
                    label="ç‰ˆæœ¬å†å² / Version History",
                    interactive=True,
                    height=200
                )
                
                # ç‰ˆæœ¬æ“ä½œæŒ‰é’®
                with gr.Row():
                    view_version_btn = gr.Button("ğŸ‘ï¸ æŸ¥çœ‹ç‰ˆæœ¬", size="sm")
                    compare_versions_btn = gr.Button("ğŸ” å¯¹æ¯”ç‰ˆæœ¬", size="sm")
                    revert_version_btn = gr.Button("â†©ï¸ å›é€€ç‰ˆæœ¬", size="sm")
                    create_milestone_btn = gr.Button("ğŸ·ï¸ åˆ›å»ºé‡Œç¨‹ç¢‘", size="sm")
            
            with gr.Column(scale=1):
                # ç‰ˆæœ¬ç»Ÿè®¡
                version_stats = gr.Plot(
                    label="ç‰ˆæœ¬ç»Ÿè®¡ / Version Statistics"
                )
                
                # ç‰ˆæœ¬å¯¹æ¯”ç»“æœ
                version_comparison = gr.HTML(
                    label="ç‰ˆæœ¬å¯¹æ¯” / Version Comparison",
                    visible=False
                )
    
    def create_configuration_section(self):
        """åˆ›å»ºç³»ç»Ÿé…ç½®åŒºåŸŸ"""
        with gr.Row():
            with gr.Column():
                gr.Markdown("### âš™ï¸ ç³»ç»Ÿè®¾ç½® / System Settings")
                
                # AWSé…ç½®
                with gr.Group():
                    gr.Markdown("#### â˜ï¸ AWSé…ç½® / AWS Configuration")
                    aws_region = gr.Dropdown(
                        choices=["us-east-1", "us-west-2", "eu-west-1"],
                        label="AWSåŒºåŸŸ / AWS Region"
                    )
                    aws_profile = gr.Textbox(label="AWS Profile")
                    test_connection_btn = gr.Button("ğŸ”— æµ‹è¯•è¿æ¥", size="sm")
                
                # æ¨¡å‹å‚æ•°é…ç½®
                with gr.Group():
                    gr.Markdown("#### ğŸ›ï¸ æ¨¡å‹å‚æ•° / Model Parameters")
                    max_tokens = gr.Slider(
                        minimum=100, maximum=8000, value=4000,
                        label="æœ€å¤§Tokenæ•° / Max Tokens"
                    )
                    temperature = gr.Slider(
                        minimum=0.0, maximum=2.0, value=0.7, step=0.1,
                        label="åˆ›é€ æ€§æ¸©åº¦ / Temperature"
                    )
                
                # ç•Œé¢è®¾ç½®
                with gr.Group():
                    gr.Markdown("#### ğŸ¨ ç•Œé¢è®¾ç½® / Interface Settings")
                    theme_selector = gr.Dropdown(
                        choices=["é»˜è®¤", "æ·±è‰²", "æµ…è‰²"],
                        label="ä¸»é¢˜ / Theme"
                    )
                    language_selector = gr.Dropdown(
                        choices=["ä¸­æ–‡", "English", "ä¸­è‹±åŒè¯­"],
                        label="è¯­è¨€ / Language"
                    )
            
            with gr.Column():
                gr.Markdown("### ğŸ“Š ç³»ç»ŸçŠ¶æ€ / System Status")
                
                # ç³»ç»Ÿä¿¡æ¯
                system_info = gr.JSON(
                    label="ç³»ç»Ÿä¿¡æ¯ / System Information",
                    value={}
                )
                
                # æ€§èƒ½ç›‘æ§
                performance_metrics = gr.Plot(
                    label="æ€§èƒ½ç›‘æ§ / Performance Metrics"
                )
                
                # æ—¥å¿—æŸ¥çœ‹
                with gr.Group():
                    gr.Markdown("#### ğŸ“‹ ç³»ç»Ÿæ—¥å¿— / System Logs")
                    log_level = gr.Dropdown(
                        choices=["DEBUG", "INFO", "WARNING", "ERROR"],
                        value="INFO",
                        label="æ—¥å¿—çº§åˆ« / Log Level"
                    )
                    system_logs = gr.Textbox(
                        label="",
                        lines=8,
                        max_lines=15,
                        interactive=False
                    )
                    refresh_logs_btn = gr.Button("ğŸ”„ åˆ·æ–°æ—¥å¿—", size="sm")
    
    def create_preference_management_section(self):
        """åˆ›å»ºä¸ªäººåå¥½ç®¡ç†åŒºåŸŸ"""
        with gr.Tabs():
            # åå¥½æ¦‚è§ˆ
            with gr.Tab("ğŸ“Š åå¥½æ¦‚è§ˆ / Preference Overview"):
                with gr.Row():
                    with gr.Column():
                        # å­¦ä¹ è¿›åº¦
                        learning_progress = gr.Plot(
                            label="å­¦ä¹ è¿›åº¦ / Learning Progress"
                        )
                        
                        # åå¥½ç»Ÿè®¡
                        preference_stats = gr.JSON(
                            label="åå¥½ç»Ÿè®¡ / Preference Statistics"
                        )
                    
                    with gr.Column():
                        # ä¸ªæ€§åŒ–å»ºè®®
                        personalized_suggestions = gr.Markdown(
                            "### ğŸ¯ ä¸ªæ€§åŒ–å»ºè®® / Personalized Suggestions\n\n"
                            "åŸºäºæ‚¨çš„ä½¿ç”¨ä¹ æƒ¯ï¼Œæˆ‘ä»¬ä¸ºæ‚¨æ¨è... / Based on your usage patterns, we recommend..."
                        )
                        
                        # åå¥½è°ƒæ•´
                        with gr.Group():
                            gr.Markdown("#### ğŸ›ï¸ åå¥½è°ƒæ•´ / Preference Adjustment")
                            
                            modification_preference = gr.Slider(
                                minimum=0, maximum=1, value=0.5,
                                label="ä¿®æ”¹å€¾å‘ / Modification Tendency"
                            )
                            
                            detail_preference = gr.Slider(
                                minimum=0, maximum=1, value=0.5,
                                label="è¯¦ç»†ç¨‹åº¦åå¥½ / Detail Level Preference"
                            )
                            
                            formality_preference = gr.Slider(
                                minimum=0, maximum=1, value=0.5,
                                label="æ­£å¼ç¨‹åº¦åå¥½ / Formality Level Preference"
                            )
            
            # æç¤ºè¯åå¥½
            with gr.Tab("ğŸ¯ æç¤ºè¯åå¥½ / Prompt Preferences"):
                prompt_preference_selector = gr.Dropdown(
                    label="é€‰æ‹©æç¤ºè¯ / Select Prompt"
                )
                
                with gr.Row():
                    with gr.Column():
                        # å½“å‰æç¤ºè¯çš„åå¥½è®¾ç½®
                        current_prompt_preferences = gr.JSON(
                            label="å½“å‰åå¥½è®¾ç½® / Current Preference Settings"
                        )
                        
                        # åå¥½å†å²
                        preference_history = gr.Dataframe(
                            headers=["æ—¶é—´", "ä¿®æ”¹ç±»å‹", "æ»¡æ„åº¦", "å­¦ä¹ æ•ˆæœ"],
                            label="åå¥½å­¦ä¹ å†å² / Preference Learning History"
                        )
                    
                    with gr.Column():
                        # åå¥½å¯è§†åŒ–
                        preference_radar = gr.Plot(
                            label="åå¥½é›·è¾¾å›¾ / Preference Radar Chart"
                        )
                        
                        # å­¦ä¹ å»ºè®®
                        learning_suggestions = gr.Markdown(
                            "### ğŸ’¡ å­¦ä¹ å»ºè®® / Learning Suggestions"
                        )
            
            # è·¨æç¤ºè¯åˆ†æ
            with gr.Tab("ğŸ”„ è·¨æç¤ºè¯åˆ†æ / Cross-Prompt Analysis"):
                cross_prompt_analysis = gr.Plot(
                    label="è·¨æç¤ºè¯åå¥½å¯¹æ¯” / Cross-Prompt Preference Comparison"
                )
                
                common_patterns = gr.JSON(
                    label="é€šç”¨åå¥½æ¨¡å¼ / Common Preference Patterns"
                )
    
    def create_data_management_section(self):
        """åˆ›å»ºæ•°æ®ç®¡ç†åŒºåŸŸ"""
        with gr.Tabs():
            # æ•°æ®å¯¼å‡ºå¯¼å…¥
            with gr.Tab("ğŸ“¤ğŸ“¥ å¯¼å‡ºå¯¼å…¥ / Export Import"):
                with gr.Row():
                    with gr.Column():
                        gr.Markdown("### ğŸ“¤ æ•°æ®å¯¼å‡º / Data Export")
                        
                        export_data_type = gr.CheckboxGroup(
                            choices=[
                                "åå¥½è®¾ç½® / Preference Settings",
                                "å¯¹è¯å†å² / Conversation History", 
                                "ç‰ˆæœ¬å†å² / Version History",
                                "å­¦ä¹ æ¨¡å‹ / Learning Models"
                            ],
                            label="é€‰æ‹©å¯¼å‡ºæ•°æ® / Select Export Data"
                        )
                        
                        export_format = gr.Dropdown(
                            choices=["JSON", "YAML", "CSV"],
                            value="JSON",
                            label="å¯¼å‡ºæ ¼å¼ / Export Format"
                        )
                        
                        export_btn = gr.Button("ğŸ“¤ å¯¼å‡ºæ•°æ®", variant="primary")
                        export_status = gr.Textbox(label="å¯¼å‡ºçŠ¶æ€ / Export Status")
                    
                    with gr.Column():
                        gr.Markdown("### ğŸ“¥ æ•°æ®å¯¼å…¥ / Data Import")
                        
                        import_file = gr.File(
                            label="é€‰æ‹©å¯¼å…¥æ–‡ä»¶ / Select Import File",
                            file_types=['.json', '.yaml', '.csv']
                        )
                        
                        import_strategy = gr.Dropdown(
                            choices=["æ›¿æ¢ / Replace", "åˆå¹¶ / Merge", "è·³è¿‡ç°æœ‰ / Skip Existing"],
                            value="åˆå¹¶ / Merge",
                            label="å¯¼å…¥ç­–ç•¥ / Import Strategy"
                        )
                        
                        validate_before_import = gr.Checkbox(
                            value=True,
                            label="å¯¼å…¥å‰éªŒè¯ / Validate Before Import"
                        )
                        
                        import_btn = gr.Button("ğŸ“¥ å¯¼å…¥æ•°æ®", variant="secondary")
                        import_status = gr.Textbox(label="å¯¼å…¥çŠ¶æ€ / Import Status")
            
            # æ•°æ®å¤‡ä»½æ¢å¤
            with gr.Tab("ğŸ’¾ å¤‡ä»½æ¢å¤ / Backup Restore"):
                with gr.Row():
                    with gr.Column():
                        gr.Markdown("### ğŸ’¾ æ•°æ®å¤‡ä»½ / Data Backup")
                        
                        backup_schedule = gr.Dropdown(
                            choices=["æ‰‹åŠ¨ / Manual", "æ¯æ—¥ / Daily", "æ¯å‘¨ / Weekly"],
                            label="å¤‡ä»½è®¡åˆ’ / Backup Schedule"
                        )
                        
                        backup_location = gr.Textbox(
                            label="å¤‡ä»½ä½ç½® / Backup Location",
                            placeholder="./backups/"
                        )
                        
                        create_backup_btn = gr.Button("åˆ›å»ºå¤‡ä»½ / Create Backup")
                        
                        # å¤‡ä»½å†å²
                        backup_history = gr.Dataframe(
                            headers=["æ—¶é—´", "å¤§å°", "çŠ¶æ€"],
                            label="å¤‡ä»½å†å² / Backup History"
                        )
                    
                    with gr.Column():
                        gr.Markdown("### ğŸ”„ æ•°æ®æ¢å¤ / Data Restore")
                        
                        restore_point = gr.Dropdown(
                            label="é€‰æ‹©æ¢å¤ç‚¹ / Select Restore Point"
                        )
                        
                        restore_scope = gr.CheckboxGroup(
                            choices=[
                                "ç”¨æˆ·åå¥½ / User Preferences",
                                "ç³»ç»Ÿé…ç½® / System Configuration",
                                "å†å²æ•°æ® / Historical Data"
                            ],
                            label="æ¢å¤èŒƒå›´ / Restore Scope"
                        )
                        
                        restore_btn = gr.Button("ğŸ”„ æ¢å¤æ•°æ®", variant="stop")
                        restore_status = gr.Textbox(label="æ¢å¤çŠ¶æ€ / Restore Status")
            
            # æ•°æ®æ¸…ç†
            with gr.Tab("ğŸ—‘ï¸ æ•°æ®æ¸…ç† / Data Cleanup"):
                gr.Markdown("### âš ï¸ æ•°æ®æ¸…ç†æ“ä½œ / Data Cleanup Operations")
                gr.Markdown("*è¯·è°¨æ…æ“ä½œï¼Œåˆ é™¤çš„æ•°æ®æ— æ³•æ¢å¤ / Please operate carefully, deleted data cannot be recovered*")
                
                cleanup_options = gr.CheckboxGroup(
                    choices=[
                        "æ¸…ç†è¿‡æœŸå¯¹è¯ / Clean Expired Conversations",
                        "æ¸…ç†æ—§ç‰ˆæœ¬æ•°æ® / Clean Old Version Data",
                        "æ¸…ç†ä¸´æ—¶æ–‡ä»¶ / Clean Temporary Files",
                        "é‡ç½®å­¦ä¹ æ¨¡å‹ / Reset Learning Models"
                    ],
                    label="æ¸…ç†é€‰é¡¹ / Cleanup Options"
                )
                
                confirm_cleanup = gr.Checkbox(
                    label="æˆ‘ç¡®è®¤æ‰§è¡Œæ¸…ç†æ“ä½œ / I confirm the cleanup operation"
                )
                
                cleanup_btn = gr.Button("ğŸ—‘ï¸ æ‰§è¡Œæ¸…ç†", variant="stop")
                cleanup_status = gr.Textbox(label="æ¸…ç†çŠ¶æ€ / Cleanup Status")
    
    def create_footer_section(self):
        """åˆ›å»ºåº•éƒ¨çŠ¶æ€å’Œå¸®åŠ©ä¿¡æ¯"""
        with gr.Row():
            with gr.Column(scale=2):
                gr.Markdown(
                    "---\n"
                    "ğŸ’¡ **ä½¿ç”¨æç¤º**: ç‚¹å‡»å„ä¸ªæ ‡ç­¾é¡µæ¢ç´¢ä¸åŒåŠŸèƒ½ï¼Œä½¿ç”¨å¯¹è¯ä¼˜åŒ–åŠŸèƒ½å¯ä»¥è®©AIæ›´å¥½åœ°ç†è§£æ‚¨çš„éœ€æ±‚ã€‚\n\n"
                    "ğŸ’¡ **Usage Tips**: Click on different tabs to explore various features. Use conversation refinement to help AI better understand your needs."
                )
            
            with gr.Column(scale=1):
                # å¿«é€Ÿç»Ÿè®¡
                quick_stats = gr.HTML(
                    value=self.get_quick_stats_html(),
                    label=""
                )
    
    def get_system_status_html(self) -> str:
        """è·å–ç³»ç»ŸçŠ¶æ€HTML"""
        return """
        <div style="text-align: center; padding: 10px; background: #f0f8ff; border-radius: 5px;">
            <span style="color: green;">â—</span> ç³»ç»Ÿæ­£å¸¸ / System Normal<br>
            <small>AWSè¿æ¥æ­£å¸¸ / AWS Connected</small>
        </div>
        """
    
    def get_quick_stats_html(self) -> str:
        """è·å–å¿«é€Ÿç»Ÿè®¡HTML"""
        return """
        <div style="text-align: center; font-size: 12px; color: #666;">
            ä»Šæ—¥ç”Ÿæˆ: 5 | æ€»å¯¹è¯: 23 | åå¥½å­¦ä¹ : 85%<br>
            Today: 5 | Total: 23 | Learning: 85%
        </div>
        """
```

### 2. åŠŸèƒ½ç»„ç»‡åŸåˆ™ / Functional Organization Principles

#### **ä¿¡æ¯æ¶æ„è®¾è®¡**
1. **ä»»åŠ¡å¯¼å‘åˆ†ç»„**: æŒ‰ç”¨æˆ·çš„ä¸»è¦ä»»åŠ¡æµç¨‹ç»„ç»‡åŠŸèƒ½
2. **æ¸è¿›å¼æŠ«éœ²**: é«˜é¢‘åŠŸèƒ½ä¼˜å…ˆæ˜¾ç¤ºï¼Œé«˜çº§åŠŸèƒ½æŠ˜å æˆ–åˆ†é¡µ
3. **è§†è§‰å±‚æ¬¡**: ä½¿ç”¨é¢œè‰²ã€å›¾æ ‡ã€é—´è·å»ºç«‹æ¸…æ™°çš„è§†è§‰å±‚æ¬¡
4. **ä¸Šä¸‹æ–‡ç›¸å…³**: ç›¸å…³åŠŸèƒ½å°±è¿‘æ”¾ç½®ï¼Œå‡å°‘ç”¨æˆ·è®¤çŸ¥è´Ÿæ‹…

#### **ç”¨æˆ·ä½“éªŒä¼˜åŒ–**
1. **ä¸€ç›®äº†ç„¶**: ç”¨æˆ·èƒ½å¿«é€Ÿç†è§£æ¯ä¸ªåŒºåŸŸçš„åŠŸèƒ½
2. **æ“ä½œä¾¿æ·**: å¸¸ç”¨æ“ä½œä¸€é”®å¯è¾¾ï¼Œå¤æ‚æ“ä½œæœ‰æ¸…æ™°æŒ‡å¼•
3. **çŠ¶æ€åé¦ˆ**: å®æ—¶æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€å’Œæ“ä½œç»“æœ
4. **é”™è¯¯é¢„é˜²**: å±é™©æ“ä½œæœ‰ç¡®è®¤æœºåˆ¶ï¼Œé‡è¦ä¿¡æ¯æœ‰å¤‡ä»½

### 3. å“åº”å¼å¸ƒå±€é€‚é… / Responsive Layout Adaptation

```python
def create_responsive_layout(self):
    """åˆ›å»ºå“åº”å¼å¸ƒå±€"""
    # æ ¹æ®å±å¹•å°ºå¯¸è°ƒæ•´å¸ƒå±€
    with gr.Column() as responsive_container:
        # ç§»åŠ¨ç«¯é€‚é…
        mobile_layout = gr.Column(visible=False)
        # æ¡Œé¢ç«¯å¸ƒå±€
        desktop_layout = gr.Column(visible=True)
        
        # JavaScriptæ£€æµ‹å±å¹•å°ºå¯¸å¹¶åˆ‡æ¢å¸ƒå±€
        screen_size_detector = gr.HTML("""
        <script>
        function detectScreenSize() {
            const isMobile = window.innerWidth < 768;
            // åˆ‡æ¢å¸ƒå±€æ˜¾ç¤º
            document.querySelector('[data-testid="mobile-layout"]').style.display = 
                isMobile ? 'block' : 'none';
            document.querySelector('[data-testid="desktop-layout"]').style.display = 
                isMobile ? 'none' : 'block';
        }
        window.addEventListener('resize', detectScreenSize);
        detectScreenSize();
        </script>
        """)
```

è¿™æ ·é‡æ–°è®¾è®¡çš„ç•Œé¢å°†å¤§å¤§æå‡ç”¨æˆ·ä½“éªŒï¼Œç¡®ä¿åŠŸèƒ½çš„å¯å‘ç°æ€§å’Œæ˜“ç”¨æ€§ï¼

## ä¸ªæ€§åŒ–åå¥½å­¦ä¹ çš„LLMæ€»ç»“æœºåˆ¶ / LLM-based Personalized Preference Learning Mechanism

### 1. åŸºäºLLMçš„åå¥½æ€»ç»“å’ŒPromptç”Ÿæˆ / LLM-based Preference Summarization and Prompt Generation

æ¯æ¬¡ç”¨æˆ·åé¦ˆåï¼Œç³»ç»Ÿè°ƒç”¨LLMæ¥æ€»ç»“ç”¨æˆ·åå¥½å¹¶ç”Ÿæˆä¸ªæ€§åŒ–promptæ–‡ä»¶ï¼š

```python
class LLMBasedPreferenceLearning:
    """åŸºäºLLMçš„åå¥½å­¦ä¹ å¼•æ“"""
    
    def __init__(self, bedrock_client: BedrockClient):
        self.bedrock_client = bedrock_client
        self.preference_prompt_template = """
        åŸºäºä»¥ä¸‹ç”¨æˆ·äº¤äº’å†å²å’Œåé¦ˆï¼Œæ€»ç»“ç”¨æˆ·åœ¨{prompt_name}åœºæ™¯ä¸‹çš„ç”Ÿæˆåå¥½ï¼š

        ## äº¤äº’å†å²
        {interaction_history}

        ## ç”¨æˆ·åé¦ˆ
        {user_feedback}

        ## å½“å‰åå¥½æ€»ç»“
        {current_preference_summary}

        è¯·åˆ†æç”¨æˆ·çš„åå¥½æ¨¡å¼ï¼Œå¹¶ç”Ÿæˆä¸€ä¸ªä¼˜åŒ–çš„ç³»ç»Ÿæç¤ºè¯ï¼ŒåŒ…å«ï¼š
        1. ç”¨æˆ·åå¥½çš„å†…å®¹é£æ ¼å’Œç»“æ„
        2. ç”¨æˆ·å¸¸è¦æ±‚çš„ä¿®æ”¹ç±»å‹
        3. ç”¨æˆ·æ»¡æ„çš„è¡¨è¾¾æ–¹å¼
        4. éœ€è¦é¿å…çš„å†…å®¹ç‰¹å¾

        è¾“å‡ºæ ¼å¼ï¼š
        ## åå¥½åˆ†æ
        [åˆ†æç”¨æˆ·åå¥½æ¨¡å¼]

        ## ä¸ªæ€§åŒ–ç³»ç»Ÿæç¤ºè¯
        [ç”Ÿæˆçš„ä¸ªæ€§åŒ–æç¤ºè¯å†…å®¹]
        """
    
    async def analyze_and_update_preference(self, user_id: str, prompt_name: str, 
                                          interaction_data: Dict) -> Dict[str, Any]:
        """åˆ†æç”¨æˆ·äº¤äº’å¹¶æ›´æ–°åå¥½"""
        
        # 1. æ”¶é›†ç”¨æˆ·äº¤äº’å†å²
        interaction_history = self.collect_interaction_history(user_id, prompt_name)
        
        # 2. è·å–å½“å‰åå¥½æ€»ç»“
        current_preference = self.load_current_preference(user_id, prompt_name)
        
        # 3. æ„å»ºLLMåˆ†ææç¤ºè¯
        analysis_prompt = self.preference_prompt_template.format(
            prompt_name=prompt_name,
            interaction_history=self.format_interaction_history(interaction_history),
            user_feedback=self.format_user_feedback(interaction_data),
            current_preference_summary=current_preference.get('summary', 'æš‚æ— åå¥½è®°å½•')
        )
        
        # 4. è°ƒç”¨LLMè¿›è¡Œåå¥½åˆ†æ
        llm_response = await self.bedrock_client.converse(
            model_id="anthropic.claude-3-5-sonnet-20241022-v2:0",
            messages=[{"role": "user", "content": analysis_prompt}],
            system_prompt="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç”¨æˆ·åå¥½åˆ†æä¸“å®¶ï¼Œæ“…é•¿ä»ç”¨æˆ·è¡Œä¸ºä¸­æ€»ç»“ä¸ªæ€§åŒ–éœ€æ±‚ã€‚",
            max_tokens=2000,
            temperature=0.3
        )
        
        # 5. è§£æLLMå“åº”
        preference_analysis = self.parse_llm_response(llm_response)
        
        # 6. ç”Ÿæˆä¸ªæ€§åŒ–promptæ–‡ä»¶
        personalized_prompt = self.create_personalized_prompt_file(
            user_id, prompt_name, preference_analysis
        )
        
        # 7. ä¿å­˜åå¥½æ›´æ–°
        await self.save_preference_update(user_id, prompt_name, {
            'analysis': preference_analysis,
            'personalized_prompt': personalized_prompt,
            'update_timestamp': datetime.now().isoformat(),
            'interaction_data': interaction_data
        })
        
        return {
            'success': True,
            'preference_analysis': preference_analysis,
            'personalized_prompt_file': personalized_prompt['file_path'],
            'prompt_version': personalized_prompt['version']
        }
    
    def create_personalized_prompt_file(self, user_id: str, prompt_name: str, 
                                      preference_analysis: Dict) -> Dict[str, Any]:
        """åˆ›å»ºä¸ªæ€§åŒ–promptæ–‡ä»¶"""
        
        # 1. ç”Ÿæˆæ–‡ä»¶è·¯å¾„å’Œç‰ˆæœ¬
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        file_name = f"{user_id}_{prompt_name}_v{timestamp}.md"
        file_path = Path(f"./personalized_prompts/{user_id}/{file_name}")
        
        # 2. ç¡®ä¿ç›®å½•å­˜åœ¨
        file_path.parent.mkdir(parents=True, exist_ok=True)
        
        # 3. æ„å»ºæ–‡ä»¶å†…å®¹
        file_content = f"""# ä¸ªæ€§åŒ–ç³»ç»Ÿæç¤ºè¯ / Personalized System Prompt

## åŸºæœ¬ä¿¡æ¯ / Basic Information
- **ç”¨æˆ·ID**: {user_id}
- **åœºæ™¯**: {prompt_name}
- **ç‰ˆæœ¬**: {timestamp}
- **åˆ›å»ºæ—¶é—´**: {datetime.now().isoformat()}

## åå¥½åˆ†æ / Preference Analysis
{preference_analysis.get('analysis', '')}

## ä¸ªæ€§åŒ–æç¤ºè¯ / Personalized Prompt
{preference_analysis.get('personalized_prompt', '')}

## ä½¿ç”¨è¯´æ˜ / Usage Instructions
æ­¤æç¤ºè¯åŸºäºç”¨æˆ·çš„å†å²äº¤äº’å’Œåé¦ˆè‡ªåŠ¨ç”Ÿæˆï¼Œä¼šéšç€ç”¨æˆ·ä½¿ç”¨ä¸æ–­ä¼˜åŒ–ã€‚
This prompt is automatically generated based on user's historical interactions and feedback, and will be continuously optimized with usage.
"""
        
        # 4. å†™å…¥æ–‡ä»¶
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(file_content)
        
        # 5. æ›´æ–°å½“å‰æ¿€æ´»çš„ä¸ªæ€§åŒ–prompt
        self.update_active_personalized_prompt(user_id, prompt_name, file_path)
        
        return {
            'file_path': str(file_path),
            'file_name': file_name,
            'version': timestamp,
            'content': file_content
        }
    
    def load_personalized_prompt(self, user_id: str, prompt_name: str) -> Optional[str]:
        """åŠ è½½ç”¨æˆ·çš„ä¸ªæ€§åŒ–prompt"""
        try:
            # 1. è·å–å½“å‰æ¿€æ´»çš„ä¸ªæ€§åŒ–promptæ–‡ä»¶
            active_prompt_file = self.get_active_personalized_prompt_file(user_id, prompt_name)
            
            if not active_prompt_file or not Path(active_prompt_file).exists():
                return None
            
            # 2. è¯»å–æ–‡ä»¶å†…å®¹
            with open(active_prompt_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # 3. æå–ä¸ªæ€§åŒ–æç¤ºè¯éƒ¨åˆ†
            personalized_prompt = self.extract_personalized_prompt_from_file(content)
            
            return personalized_prompt
            
        except Exception as e:
            logging.error(f"Failed to load personalized prompt for {user_id}/{prompt_name}: {e}")
            return None
    
    def get_personalized_prompt_versions(self, user_id: str, prompt_name: str) -> List[Dict]:
        """è·å–ä¸ªæ€§åŒ–promptçš„ç‰ˆæœ¬åˆ—è¡¨"""
        prompt_dir = Path(f"./personalized_prompts/{user_id}")
        if not prompt_dir.exists():
            return []
        
        versions = []
        pattern = f"{user_id}_{prompt_name}_v*.md"
        
        for file_path in prompt_dir.glob(pattern):
            version_info = self.parse_prompt_file_info(file_path)
            versions.append(version_info)
        
        # æŒ‰ç‰ˆæœ¬æ—¶é—´æ’åº
        versions.sort(key=lambda x: x['version'], reverse=True)
        return versions
```

### 2. ä¸ªæ€§åŒ–Promptæ–‡ä»¶ç®¡ç† / Personalized Prompt File Management

```python
class PersonalizedPromptManager:
    """ä¸ªæ€§åŒ–Promptæ–‡ä»¶ç®¡ç†å™¨"""
    
    def __init__(self, base_path: str = "./personalized_prompts"):
        self.base_path = Path(base_path)
        self.base_path.mkdir(parents=True, exist_ok=True)
        
    def export_personalized_prompts(self, user_id: str, export_format: str = 'json') -> Dict:
        """å¯¼å‡ºç”¨æˆ·çš„ä¸ªæ€§åŒ–promptæ–‡ä»¶"""
        user_dir = self.base_path / user_id
        if not user_dir.exists():
            return {'success': False, 'error': 'No personalized prompts found'}
        
        export_data = {
            'user_id': user_id,
            'export_timestamp': datetime.now().isoformat(),
            'prompts': {}
        }
        
        # æ”¶é›†æ‰€æœ‰promptæ–‡ä»¶
        for prompt_file in user_dir.glob("*.md"):
            prompt_info = self.parse_prompt_file_info(prompt_file)
            prompt_name = prompt_info['prompt_name']
            
            if prompt_name not in export_data['prompts']:
                export_data['prompts'][prompt_name] = []
            
            export_data['prompts'][prompt_name].append({
                'version': prompt_info['version'],
                'file_name': prompt_file.name,
                'content': prompt_file.read_text(encoding='utf-8'),
                'created_at': prompt_info['created_at']
            })
        
        # ç”Ÿæˆå¯¼å‡ºæ–‡ä»¶
        export_filename = f"personalized_prompts_{user_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.{export_format}"
        
        if export_format == 'json':
            export_content = json.dumps(export_data, ensure_ascii=False, indent=2)
        elif export_format == 'yaml':
            export_content = yaml.dump(export_data, allow_unicode=True, default_flow_style=False)
        
        return {
            'success': True,
            'filename': export_filename,
            'content': export_content,
            'data': export_data
        }
    
    def import_personalized_prompts(self, import_data: Dict, target_user_id: str = None) -> Dict:
        """å¯¼å…¥ä¸ªæ€§åŒ–promptæ–‡ä»¶"""
        try:
            user_id = target_user_id or import_data['user_id']
            user_dir = self.base_path / user_id
            user_dir.mkdir(parents=True, exist_ok=True)
            
            imported_count = 0
            
            for prompt_name, prompt_versions in import_data['prompts'].items():
                for version_data in prompt_versions:
                    # é‡æ–°ç”Ÿæˆæ–‡ä»¶åä»¥é¿å…å†²çª
                    new_filename = f"{user_id}_{prompt_name}_imported_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
                    file_path = user_dir / new_filename
                    
                    # å†™å…¥æ–‡ä»¶
                    file_path.write_text(version_data['content'], encoding='utf-8')
                    imported_count += 1
            
            return {
                'success': True,
                'imported_count': imported_count,
                'target_user': user_id
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }
```

### 3. é›†æˆåˆ°ç°æœ‰ç³»ç»Ÿæç¤ºè¯ç®¡ç† / Integration with Existing System Prompt Management

```python
class EnhancedSystemPromptManager:
    """å¢å¼ºçš„ç³»ç»Ÿæç¤ºè¯ç®¡ç†å™¨ï¼Œé›†æˆä¸ªæ€§åŒ–åŠŸèƒ½"""
    
    def __init__(self, config_manager, history_processor):
        self.config_manager = config_manager
        self.history_processor = history_processor
        self.personalized_prompt_manager = PersonalizedPromptManager()
        self.llm_preference_learning = LLMBasedPreferenceLearning(bedrock_client)
    
    def get_effective_prompt(self, user_id: str, prompt_name: str) -> str:
        """è·å–æœ‰æ•ˆçš„æç¤ºè¯ï¼ˆä¼˜å…ˆä½¿ç”¨ä¸ªæ€§åŒ–ç‰ˆæœ¬ï¼‰"""
        
        # 1. å°è¯•åŠ è½½ä¸ªæ€§åŒ–prompt
        personalized_prompt = self.personalized_prompt_manager.load_personalized_prompt(
            user_id, prompt_name
        )
        
        if personalized_prompt:
            return personalized_prompt
        
        # 2. å›é€€åˆ°åŸºç¡€ç³»ç»Ÿæç¤ºè¯
        base_prompt = self.get_base_prompt(prompt_name)
        return base_prompt
    
    async def update_preference_from_feedback(self, user_id: str, prompt_name: str, 
                                           feedback_data: Dict) -> None:
        """æ ¹æ®ç”¨æˆ·åé¦ˆæ›´æ–°åå¥½"""
        
        # è°ƒç”¨LLMè¿›è¡Œåå¥½åˆ†æå’Œpromptç”Ÿæˆ
        result = await self.llm_preference_learning.analyze_and_update_preference(
            user_id, prompt_name, feedback_data
        )
        
        if result['success']:
            logging.info(f"Updated personalized prompt for {user_id}/{prompt_name}")
        else:
            logging.error(f"Failed to update personalized prompt: {result.get('error')}")
```

## æ ¸å¿ƒç®—æ³•è®¾è®¡ / Core Algorithm Design

### 1. ä¸Šä¸‹æ–‡æ„ŸçŸ¥ç®—æ³• / Context Awareness Algorithm

```python
class ContextAwarenessEngine:
    """ä¸Šä¸‹æ–‡æ„ŸçŸ¥å¼•æ“"""
    
    def __init__(self):
        self.context_window_size = 10  # ä¿ç•™æœ€è¿‘10è½®å¯¹è¯
        self.relevance_threshold = 0.7
        
    def extract_relevant_context(self, conversation_history: List[ConversationMessage], 
                               current_query: str) -> str:
        """æå–ç›¸å…³ä¸Šä¸‹æ–‡"""
        # 1. è®¡ç®—æ¶ˆæ¯ç›¸å…³æ€§å¾—åˆ†
        scored_messages = []
        for message in conversation_history[-self.context_window_size:]:
            relevance_score = self.calculate_relevance(message.content, current_query)
            if relevance_score > self.relevance_threshold:
                scored_messages.append((message, relevance_score))
        
        # 2. æŒ‰ç›¸å…³æ€§æ’åºå¹¶æ„å»ºä¸Šä¸‹æ–‡
        scored_messages.sort(key=lambda x: x[1], reverse=True)
        context_parts = []
        
        for message, score in scored_messages[:5]:  # æœ€å¤šä¿ç•™5æ¡ç›¸å…³æ¶ˆæ¯
            context_parts.append(f"[{message.sender}]: {message.content}")
            
        return "\n".join(context_parts)
    
    def calculate_relevance(self, message_content: str, query: str) -> float:
        """è®¡ç®—æ¶ˆæ¯ä¸æŸ¥è¯¢çš„ç›¸å…³æ€§"""
        # ä½¿ç”¨ç®€å•çš„å…³é”®è¯åŒ¹é…å’Œè¯­ä¹‰ç›¸ä¼¼åº¦
        # å®é™…å®ç°å¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„NLPç®—æ³•
        common_words = set(message_content.lower().split()) & set(query.lower().split())
        return len(common_words) / max(len(query.split()), 1)
```

### 2. ä¿®æ”¹æ„å›¾è¯†åˆ«ç®—æ³• / Modification Intent Recognition Algorithm

```python
class ModificationIntentClassifier:
    """ä¿®æ”¹æ„å›¾åˆ†ç±»å™¨"""
    
    def __init__(self):
        self.intent_patterns = {
            ModificationType.STRUCTURAL: [
                r"æ·»åŠ .*éƒ¨åˆ†", r"å¢åŠ .*ç« èŠ‚", r"é‡æ–°ç»„ç»‡", r"è°ƒæ•´ç»“æ„"
            ],
            ModificationType.CONTENT_ADDITION: [
                r"è¯¦ç»†è¯´æ˜", r"è¡¥å…….*ä¿¡æ¯", r"æ·»åŠ .*å†…å®¹", r"æ‰©å±•"
            ],
            ModificationType.CONTENT_REMOVAL: [
                r"åˆ é™¤", r"ç§»é™¤", r"å»æ‰", r"ç®€åŒ–"
            ],
            ModificationType.STYLE_ADJUSTMENT: [
                r"æ›´.*é£æ ¼", r"æ”¹å˜è¯­æ°”", r"è°ƒæ•´è¡¨è¾¾", r"æ›´æ­£å¼", r"æ›´é€šä¿—"
            ]
        }
    
    def classify_modification_intent(self, user_request: str) -> ModificationPlan:
        """åˆ†ç±»ä¿®æ”¹æ„å›¾"""
        # 1. æ¨¡å¼åŒ¹é…
        detected_types = []
        for mod_type, patterns in self.intent_patterns.items():
            for pattern in patterns:
                if re.search(pattern, user_request):
                    detected_types.append(mod_type)
                    break
        
        # 2. ç¡®å®šä¸»è¦ä¿®æ”¹ç±»å‹
        primary_type = detected_types[0] if detected_types else ModificationType.CONTENT_ADDITION
        
        # 3. æå–ç›®æ ‡åŒºåŸŸ
        target_sections = self.extract_target_sections(user_request)
        
        # 4. ç”Ÿæˆä¿®æ”¹æŒ‡ä»¤
        instructions = self.generate_instructions(user_request, primary_type)
        
        return ModificationPlan(
            id=self.generate_plan_id(),
            request=user_request,
            modification_type=primary_type,
            target_sections=target_sections,
            instructions=instructions,
            estimated_impact=self.estimate_impact(primary_type, target_sections),
            confidence_score=0.8  # ç®€åŒ–çš„ç½®ä¿¡åº¦è®¡ç®—
        )
```

### 3. ä¸ªæ€§åŒ–åå¥½å­¦ä¹ ç®—æ³• / Personalized Preference Learning Algorithm

```python
@dataclass
class UserPreferenceProfile:
    """ç”¨æˆ·åå¥½æ¡£æ¡ˆ"""
    user_id: str
    prompt_name: str  # å…³è”çš„ç³»ç»Ÿæç¤ºè¯
    modification_preferences: Dict[str, float]  # ä¿®æ”¹ç±»å‹åå¥½æƒé‡
    style_preferences: Dict[str, Any]  # è¯­è¨€é£æ ¼åå¥½
    interaction_patterns: Dict[str, Any]  # äº¤äº’æ¨¡å¼åå¥½
    content_structure_preferences: Dict[str, Any]  # å†…å®¹ç»“æ„åå¥½
    success_history: List[Dict]  # æˆåŠŸä¿®æ”¹å†å²
    created_at: datetime
    updated_at: datetime

class PreferenceLearningEngine:
    """åå¥½å­¦ä¹ å¼•æ“ - æ”¯æŒç³»ç»Ÿæç¤ºè¯çº§åˆ«çš„ä¸ªæ€§åŒ–å­¦ä¹ """
    
    def __init__(self, system_prompt_manager):
        self.system_prompt_manager = system_prompt_manager
        # ä¸ºæ¯ä¸ªç³»ç»Ÿæç¤ºè¯ç»´æŠ¤ç‹¬ç«‹çš„åå¥½æ¨¡å‹
        self.prompt_preferences = {}  # {prompt_name: {user_id: UserPreferenceProfile}}
        self.learning_rate = 0.1
        self.preference_decay_rate = 0.95  # åå¥½è¡°å‡ç‡ï¼Œé¿å…è¿‡åº¦æ‹Ÿåˆ
        
    def get_user_preference_profile(self, user_id: str, prompt_name: str) -> UserPreferenceProfile:
        """è·å–ç”¨æˆ·åœ¨ç‰¹å®šç³»ç»Ÿæç¤ºè¯ä¸‹çš„åå¥½æ¡£æ¡ˆ"""
        if prompt_name not in self.prompt_preferences:
            self.prompt_preferences[prompt_name] = {}
            
        if user_id not in self.prompt_preferences[prompt_name]:
            # åˆ›å»ºæ–°çš„åå¥½æ¡£æ¡ˆ
            self.prompt_preferences[prompt_name][user_id] = UserPreferenceProfile(
                user_id=user_id,
                prompt_name=prompt_name,
                modification_preferences=self.initialize_modification_preferences(),
                style_preferences=self.initialize_style_preferences(),
                interaction_patterns=self.initialize_interaction_patterns(),
                content_structure_preferences=self.initialize_structure_preferences(),
                success_history=[],
                created_at=datetime.now(),
                updated_at=datetime.now()
            )
        
        return self.prompt_preferences[prompt_name][user_id]
    
    def update_preferences_from_interaction(self, user_id: str, prompt_name: str, 
                                          interaction_data: Dict) -> None:
        """ä»ç”¨æˆ·äº¤äº’ä¸­æ›´æ–°åå¥½"""
        profile = self.get_user_preference_profile(user_id, prompt_name)
        
        # 1. æ›´æ–°ä¿®æ”¹ç±»å‹åå¥½
        if 'modification_type' in interaction_data:
            mod_type = interaction_data['modification_type']
            success_score = interaction_data.get('user_satisfaction', 0.5)
            
            current_weight = profile.modification_preferences.get(mod_type, 0.5)
            new_weight = current_weight + self.learning_rate * (success_score - current_weight)
            profile.modification_preferences[mod_type] = new_weight
        
        # 2. æ›´æ–°è¯­è¨€é£æ ¼åå¥½
        if 'style_feedback' in interaction_data:
            style_data = interaction_data['style_feedback']
            for style_aspect, preference in style_data.items():
                profile.style_preferences[style_aspect] = preference
        
        # 3. æ›´æ–°äº¤äº’æ¨¡å¼åå¥½
        if 'interaction_pattern' in interaction_data:
            pattern = interaction_data['interaction_pattern']
            profile.interaction_patterns[pattern['type']] = pattern['effectiveness']
        
        # 4. è®°å½•æˆåŠŸå†å²
        if interaction_data.get('success', False):
            profile.success_history.append({
                'timestamp': datetime.now(),
                'modification_type': interaction_data.get('modification_type'),
                'satisfaction_score': interaction_data.get('user_satisfaction', 0.5),
                'content_length_before': interaction_data.get('content_length_before'),
                'content_length_after': interaction_data.get('content_length_after'),
                'modification_complexity': interaction_data.get('complexity_score', 0.5)
            })
        
        # 5. åº”ç”¨åå¥½è¡°å‡ï¼Œé¿å…è¿‡åº¦æ‹Ÿåˆ
        self.apply_preference_decay(profile)
        
        profile.updated_at = datetime.now()
    
    def generate_personalized_guidance(self, user_id: str, prompt_name: str, 
                                     current_content: str, context: str) -> Dict[str, Any]:
        """ä¸ºåç»­ç”Ÿæˆæä¾›ä¸ªæ€§åŒ–æŒ‡å¼•"""
        profile = self.get_user_preference_profile(user_id, prompt_name)
        
        guidance = {
            'preferred_modification_types': self.get_top_preferred_modifications(profile),
            'style_guidance': self.generate_style_guidance(profile, current_content),
            'structure_suggestions': self.generate_structure_suggestions(profile, current_content),
            'interaction_recommendations': self.generate_interaction_recommendations(profile),
            'proactive_suggestions': self.generate_proactive_suggestions(profile, current_content, context)
        }
        
        return guidance
    
    def get_top_preferred_modifications(self, profile: UserPreferenceProfile) -> List[Dict]:
        """è·å–ç”¨æˆ·æœ€åå¥½çš„ä¿®æ”¹ç±»å‹"""
        sorted_prefs = sorted(
            profile.modification_preferences.items(), 
            key=lambda x: x[1], 
            reverse=True
        )
        
        return [
            {
                'type': mod_type,
                'weight': weight,
                'description': self.get_modification_description(mod_type)
            }
            for mod_type, weight in sorted_prefs[:3] if weight > 0.6
        ]
    
    def generate_style_guidance(self, profile: UserPreferenceProfile, content: str) -> Dict[str, Any]:
        """ç”Ÿæˆè¯­è¨€é£æ ¼æŒ‡å¼•"""
        style_prefs = profile.style_preferences
        
        guidance = {
            'formality_level': style_prefs.get('formality', 'balanced'),  # formal/informal/balanced
            'detail_level': style_prefs.get('detail_preference', 'moderate'),  # detailed/concise/moderate
            'technical_depth': style_prefs.get('technical_depth', 'appropriate'),  # deep/surface/appropriate
            'tone': style_prefs.get('tone', 'professional'),  # professional/friendly/authoritative
            'preferred_sentence_length': style_prefs.get('sentence_length', 'mixed')  # short/long/mixed
        }
        
        # åŸºäºå½“å‰å†…å®¹åˆ†æï¼Œæä¾›å…·ä½“å»ºè®®
        current_style = self.analyze_current_style(content)
        guidance['adjustment_suggestions'] = self.compare_styles(current_style, style_prefs)
        
        return guidance
    
    def generate_proactive_suggestions(self, profile: UserPreferenceProfile, 
                                     current_content: str, context: str) -> List[str]:
        """ç”Ÿæˆä¸»åŠ¨å»ºè®®"""
        suggestions = []
        
        # åŸºäºå†å²æˆåŠŸæ¨¡å¼ç”Ÿæˆå»ºè®®
        successful_patterns = self.analyze_success_patterns(profile.success_history)
        
        for pattern in successful_patterns:
            if self.is_pattern_applicable(pattern, current_content, context):
                suggestion = self.generate_suggestion_from_pattern(pattern, current_content)
                suggestions.append(suggestion)
        
        # åŸºäºç³»ç»Ÿæç¤ºè¯ç‰¹æ€§ç”Ÿæˆå»ºè®®
        prompt_specific_suggestions = self.generate_prompt_specific_suggestions(
            profile.prompt_name, current_content, profile
        )
        suggestions.extend(prompt_specific_suggestions)
        
        return suggestions[:5]  # æœ€å¤šè¿”å›5ä¸ªä¸»åŠ¨å»ºè®®
    
    def cross_prompt_learning(self, user_id: str) -> None:
        """è·¨ç³»ç»Ÿæç¤ºè¯çš„åå¥½å­¦ä¹ """
        user_profiles = []
        
        # æ”¶é›†ç”¨æˆ·åœ¨æ‰€æœ‰ç³»ç»Ÿæç¤ºè¯ä¸‹çš„åå¥½æ¡£æ¡ˆ
        for prompt_name, prompt_users in self.prompt_preferences.items():
            if user_id in prompt_users:
                user_profiles.append(prompt_users[user_id])
        
        if len(user_profiles) < 2:
            return  # éœ€è¦è‡³å°‘2ä¸ªæ¡£æ¡ˆæ‰èƒ½è¿›è¡Œè·¨æç¤ºè¯å­¦ä¹ 
        
        # è¯†åˆ«é€šç”¨åå¥½æ¨¡å¼
        common_patterns = self.identify_common_patterns(user_profiles)
        
        # å°†é€šç”¨æ¨¡å¼åº”ç”¨åˆ°åå¥½è¾ƒå°‘çš„æ¡£æ¡ˆä¸­
        for profile in user_profiles:
            if len(profile.success_history) < 5:  # ç»éªŒè¾ƒå°‘çš„æ¡£æ¡ˆ
                self.apply_common_patterns(profile, common_patterns)
    
    def generate_learning_insights(self, user_id: str, prompt_name: str) -> Dict[str, Any]:
        """ç”Ÿæˆå­¦ä¹ æ´å¯ŸæŠ¥å‘Š"""
        profile = self.get_user_preference_profile(user_id, prompt_name)
        
        insights = {
            'preference_summary': {
                'dominant_modification_types': self.get_top_preferred_modifications(profile),
                'style_profile': profile.style_preferences,
                'interaction_efficiency': self.calculate_interaction_efficiency(profile)
            },
            'learning_progress': {
                'total_interactions': len(profile.success_history),
                'success_rate': self.calculate_success_rate(profile),
                'preference_stability': self.calculate_preference_stability(profile)
            },
            'recommendations': {
                'optimization_suggestions': self.generate_optimization_suggestions(profile),
                'learning_opportunities': self.identify_learning_opportunities(profile)
            }
        }
        
        return insights
```

## æ€§èƒ½ä¼˜åŒ–è®¾è®¡ / Performance Optimization Design

### 1. å¼‚æ­¥å¤„ç†æ¶æ„ / Asynchronous Processing Architecture

```python
class AsyncRefinementProcessor:
    """å¼‚æ­¥ä¼˜åŒ–å¤„ç†å™¨"""
    
    def __init__(self):
        self.task_queue = asyncio.Queue()
        self.worker_pool = []
        self.max_workers = 5
        
    async def start_workers(self):
        """å¯åŠ¨å·¥ä½œçº¿ç¨‹æ± """
        for i in range(self.max_workers):
            worker = asyncio.create_task(self.worker_loop(f"worker-{i}"))
            self.worker_pool.append(worker)
    
    async def worker_loop(self, worker_id: str):
        """å·¥ä½œçº¿ç¨‹å¾ªç¯"""
        while True:
            try:
                task = await self.task_queue.get()
                await self.process_task(task)
                self.task_queue.task_done()
            except Exception as e:
                logging.error(f"Worker {worker_id} error: {e}")
    
    async def submit_modification_task(self, task: ModificationTask) -> str:
        """æäº¤ä¿®æ”¹ä»»åŠ¡"""
        await self.task_queue.put(task)
        return task.id
```

### 2. ç¼“å­˜ç­–ç•¥ / Caching Strategy

```python
class RefinementCache:
    """ä¼˜åŒ–åŠŸèƒ½ç¼“å­˜"""
    
    def __init__(self):
        self.conversation_cache = {}
        self.version_cache = {}
        self.preference_cache = {}
        self.cache_ttl = 3600  # 1å°æ—¶è¿‡æœŸ
        
    def cache_conversation(self, session_id: str, conversation: ConversationSession):
        """ç¼“å­˜å¯¹è¯ä¼šè¯"""
        self.conversation_cache[session_id] = {
            'data': conversation,
            'timestamp': time.time()
        }
    
    def get_cached_conversation(self, session_id: str) -> Optional[ConversationSession]:
        """è·å–ç¼“å­˜çš„å¯¹è¯ä¼šè¯"""
        if session_id in self.conversation_cache:
            cache_entry = self.conversation_cache[session_id]
            if time.time() - cache_entry['timestamp'] < self.cache_ttl:
                return cache_entry['data']
            else:
                del self.conversation_cache[session_id]
        return None
```

## é”™è¯¯å¤„ç†å’Œæ¢å¤ / Error Handling and Recovery

### 1. é”™è¯¯åˆ†ç±»å’Œå¤„ç†ç­–ç•¥ / Error Classification and Handling Strategy

```python
class RefinementErrorHandler:
    """ä¼˜åŒ–åŠŸèƒ½é”™è¯¯å¤„ç†å™¨"""
    
    def __init__(self):
        self.error_handlers = {
            ConversationError: self.handle_conversation_error,
            VersionError: self.handle_version_error,
            ModificationError: self.handle_modification_error,
            PreferenceError: self.handle_preference_error
        }
    
    async def handle_error(self, error: Exception, context: Dict) -> ErrorResponse:
        """ç»Ÿä¸€é”™è¯¯å¤„ç†å…¥å£"""
        error_type = type(error)
        if error_type in self.error_handlers:
            return await self.error_handlers[error_type](error, context)
        else:
            return await self.handle_unknown_error(error, context)
    
    async def handle_conversation_error(self, error: ConversationError, context: Dict) -> ErrorResponse:
        """å¤„ç†å¯¹è¯ç›¸å…³é”™è¯¯"""
        if isinstance(error, ConversationTimeoutError):
            # å°è¯•æ¢å¤å¯¹è¯çŠ¶æ€
            session_id = context.get('session_id')
            if session_id:
                await self.recover_conversation_state(session_id)
            
        return ErrorResponse(
            error_code="CONVERSATION_ERROR",
            message="å¯¹è¯å¤„ç†å‡ºç°é—®é¢˜ï¼Œå·²å°è¯•è‡ªåŠ¨æ¢å¤",
            recovery_action="retry_last_message"
        )
```

### 2. çŠ¶æ€æ¢å¤æœºåˆ¶ / State Recovery Mechanism

```python
class StateRecoveryManager:
    """çŠ¶æ€æ¢å¤ç®¡ç†å™¨"""
    
    def __init__(self):
        self.checkpoint_interval = 300  # 5åˆ†é’Ÿåˆ›å»ºä¸€æ¬¡æ£€æŸ¥ç‚¹
        self.recovery_strategies = {}
        
    async def create_checkpoint(self, session_id: str):
        """åˆ›å»ºçŠ¶æ€æ£€æŸ¥ç‚¹"""
        session_state = await self.get_session_state(session_id)
        checkpoint = {
            'session_id': session_id,
            'timestamp': time.time(),
            'conversation_state': session_state.conversation,
            'version_state': session_state.versions,
            'preference_state': session_state.preferences
        }
        await self.save_checkpoint(checkpoint)
    
    async def recover_from_checkpoint(self, session_id: str) -> bool:
        """ä»æ£€æŸ¥ç‚¹æ¢å¤çŠ¶æ€"""
        try:
            checkpoint = await self.load_latest_checkpoint(session_id)
            if checkpoint:
                await self.restore_session_state(session_id, checkpoint)
                return True
        except Exception as e:
            logging.error(f"Failed to recover from checkpoint: {e}")
        return False
```

## å®‰å…¨æ€§è®¾è®¡ / Security Design

### 1. è¾“å…¥éªŒè¯å’Œæ¸…ç† / Input Validation and Sanitization

```python
class InputValidator:
    """è¾“å…¥éªŒè¯å™¨"""
    
    def __init__(self):
        self.max_message_length = 2000
        self.forbidden_patterns = [
            r'<script.*?>.*?</script>',
            r'javascript:',
            r'on\w+\s*=',
        ]
    
    def validate_user_message(self, message: str) -> ValidationResult:
        """éªŒè¯ç”¨æˆ·æ¶ˆæ¯"""
        # é•¿åº¦æ£€æŸ¥
        if len(message) > self.max_message_length:
            return ValidationResult(False, "æ¶ˆæ¯é•¿åº¦è¶…å‡ºé™åˆ¶")
        
        # æ¶æ„å†…å®¹æ£€æŸ¥
        for pattern in self.forbidden_patterns:
            if re.search(pattern, message, re.IGNORECASE):
                return ValidationResult(False, "æ¶ˆæ¯åŒ…å«ä¸å®‰å…¨å†…å®¹")
        
        # HTMLæ ‡ç­¾æ¸…ç†
        cleaned_message = self.sanitize_html(message)
        
        return ValidationResult(True, "éªŒè¯é€šè¿‡", cleaned_message)
```

### 2. æ•°æ®åŠ å¯†å’Œéšç§ä¿æŠ¤ / Data Encryption and Privacy Protection

```python
class PrivacyProtectionManager:
    """éšç§ä¿æŠ¤ç®¡ç†å™¨"""
    
    def __init__(self, encryption_key: str):
        self.encryption_key = encryption_key
        self.cipher = Fernet(encryption_key.encode())
    
    def encrypt_sensitive_data(self, data: Dict) -> str:
        """åŠ å¯†æ•æ„Ÿæ•°æ®"""
        json_data = json.dumps(data)
        encrypted_data = self.cipher.encrypt(json_data.encode())
        return base64.b64encode(encrypted_data).decode()
    
    def decrypt_sensitive_data(self, encrypted_data: str) -> Dict:
        """è§£å¯†æ•æ„Ÿæ•°æ®"""
        encrypted_bytes = base64.b64decode(encrypted_data.encode())
        decrypted_data = self.cipher.decrypt(encrypted_bytes)
        return json.loads(decrypted_data.decode())
```

## æµ‹è¯•ç­–ç•¥ / Testing Strategy

### 1. å•å…ƒæµ‹è¯•è®¾è®¡ / Unit Testing Design

```python
class TestRefinementController(unittest.TestCase):
    """ä¼˜åŒ–æ§åˆ¶å™¨å•å…ƒæµ‹è¯•"""
    
    def setUp(self):
        self.mock_app_controller = Mock()
        self.refinement_controller = RefinementController(self.mock_app_controller)
    
    async def test_start_refinement_session(self):
        """æµ‹è¯•å¯åŠ¨ä¼˜åŒ–ä¼šè¯"""
        initial_content = "æµ‹è¯•å†…å®¹"
        user_id = "test_user"
        
        session_id = await self.refinement_controller.start_refinement_session(
            initial_content, user_id
        )
        
        self.assertIsNotNone(session_id)
        self.assertTrue(session_id.startswith("session_"))
    
    async def test_process_user_message(self):
        """æµ‹è¯•å¤„ç†ç”¨æˆ·æ¶ˆæ¯"""
        # è®¾ç½®æµ‹è¯•æ•°æ®
        session_id = "test_session"
        message = "è¯·æ·»åŠ é£é™©è¯„ä¼°éƒ¨åˆ†"
        
        # æ‰§è¡Œæµ‹è¯•
        result = await self.refinement_controller.process_user_message(
            message, session_id
        )
        
        # éªŒè¯ç»“æœ
        self.assertIn('response', result)
        self.assertIn('modified_content', result)
```

### 2. é›†æˆæµ‹è¯•è®¾è®¡ / Integration Testing Design

```python
class TestRefinementIntegration(unittest.TestCase):
    """ä¼˜åŒ–åŠŸèƒ½é›†æˆæµ‹è¯•"""
    
    def setUp(self):
        self.app_controller = AppController("test_config.yaml")
        self.refinement_controller = RefinementController(self.app_controller)
    
    async def test_end_to_end_refinement_flow(self):
        """æµ‹è¯•ç«¯åˆ°ç«¯ä¼˜åŒ–æµç¨‹"""
        # 1. å¯åŠ¨ä¼šè¯
        session_id = await self.refinement_controller.start_refinement_session(
            "åˆå§‹å†…å®¹", "test_user"
        )
        
        # 2. å‘é€ä¿®æ”¹è¯·æ±‚
        result = await self.refinement_controller.process_user_message(
            "è¯·æ·»åŠ ç»“è®ºéƒ¨åˆ†", session_id
        )
        
        # 3. éªŒè¯ç‰ˆæœ¬åˆ›å»º
        versions = self.refinement_controller.get_version_history(session_id)
        self.assertEqual(len(versions), 2)  # åˆå§‹ç‰ˆæœ¬ + ä¿®æ”¹ç‰ˆæœ¬
        
        # 4. æµ‹è¯•ç‰ˆæœ¬å›é€€
        reverted_content = self.refinement_controller.revert_to_version(
            session_id, versions[0]['id']
        )
        self.assertEqual(reverted_content, "åˆå§‹å†…å®¹")
```

## éƒ¨ç½²å’Œç›‘æ§ / Deployment and Monitoring

### 1. éƒ¨ç½²é…ç½® / Deployment Configuration

```yaml
# ä¼˜åŒ–åŠŸèƒ½é…ç½®
refinement:
  # å¯¹è¯ç®¡ç†é…ç½®
  conversation:
    max_sessions_per_user: 5
    session_timeout: 3600  # 1å°æ—¶
    max_messages_per_session: 100
    context_window_size: 10
  
  # ç‰ˆæœ¬ç®¡ç†é…ç½®
  version:
    max_versions_per_session: 50
    auto_cleanup_enabled: true
    milestone_retention_days: 30
  
  # æ€§èƒ½é…ç½®
  performance:
    max_concurrent_modifications: 10
    cache_ttl: 3600
    async_processing_enabled: true
  
  # å®‰å…¨é…ç½®
  security:
    input_validation_enabled: true
    max_message_length: 2000
    encryption_enabled: true
```

### 2. ç›‘æ§æŒ‡æ ‡ / Monitoring Metrics

```python
class RefinementMetrics:
    """ä¼˜åŒ–åŠŸèƒ½ç›‘æ§æŒ‡æ ‡"""
    
    def __init__(self):
        self.metrics = {
            'active_sessions': 0,
            'total_messages_processed': 0,
            'successful_modifications': 0,
            'failed_modifications': 0,
            'average_response_time': 0.0,
            'cache_hit_rate': 0.0,
            'user_satisfaction_score': 0.0
        }
    
    def record_message_processed(self, processing_time: float):
        """è®°å½•æ¶ˆæ¯å¤„ç†æŒ‡æ ‡"""
        self.metrics['total_messages_processed'] += 1
        self.update_average_response_time(processing_time)
    
    def record_modification_result(self, success: bool):
        """è®°å½•ä¿®æ”¹ç»“æœæŒ‡æ ‡"""
        if success:
            self.metrics['successful_modifications'] += 1
        else:
            self.metrics['failed_modifications'] += 1
```

è¿™ä¸ªè®¾è®¡æ–‡æ¡£è¯¦ç»†æè¿°äº†äº¤äº’å¼å†…å®¹ä¼˜åŒ–åŠŸèƒ½çš„å®Œæ•´æ¶æ„ï¼ŒåŒ…æ‹¬ç³»ç»Ÿé›†æˆã€æ ¸å¿ƒç®—æ³•ã€ç”¨æˆ·ç•Œé¢ã€æ€§èƒ½ä¼˜åŒ–ã€å®‰å…¨æ€§å’Œæµ‹è¯•ç­–ç•¥ã€‚è¯¥è®¾è®¡ç¡®ä¿äº†åŠŸèƒ½çš„å¯æ‰©å±•æ€§ã€å¯ç»´æŠ¤æ€§å’Œä¸ç°æœ‰ç³»ç»Ÿçš„æ— ç¼é›†æˆã€‚